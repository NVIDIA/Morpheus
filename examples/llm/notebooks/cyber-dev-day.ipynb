{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2941e94f-db20-44a5-ab87-2cab499825f7",
   "metadata": {},
   "source": [
    "# Cyber Developer Day 2024\n",
    "## Introduction\n",
    "\n",
    "TODO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a60d2a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "# Ensure that the morpheus directory is in the python path. This may not need to be run depending on the environment setup\n",
    "import sys\n",
    "import os\n",
    "\n",
    "if (\"MORPHEUS_ROOT\" not in os.environ):\n",
    "    os.environ[\"MORPHEUS_ROOT\"] = os.path.abspath(\"../../..\")\n",
    "\n",
    "llm_dir = os.path.abspath(os.path.join(os.getenv(\"MORPHEUS_ROOT\", \"../../..\"), \"examples\", \"llm\"))\n",
    "\n",
    "if (llm_dir not in sys.path):\n",
    "    sys.path.append(llm_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef295094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that the current environment is set up with API keys\n",
    "required_env_vars = [\n",
    "    \"MORPHEUS_ROOT\",\n",
    "    \"NGC_API_KEY\",\n",
    "    \"NVIDIA_API_KEY\",\n",
    "]\n",
    "\n",
    "if (not all([var in os.environ for var in required_env_vars])):\n",
    "\n",
    "    # Try loading an .env file if it exists\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "\n",
    "    # Check again\n",
    "    if (not all([var in os.environ for var in required_env_vars])):\n",
    "        raise ValueError(f\"Please set the following environment variables: {required_env_vars}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2aa2691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global imports\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9ab76ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "import logging\n",
    "from morpheus.config import CppConfig\n",
    "from morpheus.utils.logger import configure_logging\n",
    "\n",
    "# Configure the logging\n",
    "configure_logging(log_level=logging.INFO)\n",
    "\n",
    "morpheus_logger = logging.getLogger(\"morpheus\")\n",
    "\n",
    "logger = logging.getLogger('.'.join(__name__.split('.')[:-1]))\n",
    "\n",
    "# Set the parent logger for all of the llm examples to use morpheus so we can take advantage of configure_logging\n",
    "logger.parent = morpheus_logger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb62b83",
   "metadata": {},
   "source": [
    "## Part 1 - Intro to Interacting with LLMs\n",
    "\n",
    "This section will go over how to integrate LLMs into code with GUI or Python based examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afdc87a",
   "metadata": {},
   "source": [
    "## Part 2 - Prototyping\n",
    "\n",
    "Building a Pipeline with LLMs to Analyze CVEs\n",
    "\n",
    "### Overview\n",
    "\n",
    "Background of RAG, data sources, building vector databases\n",
    "\n",
    "### Building the Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c5175d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to build the Vector Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0cd628",
   "metadata": {},
   "source": [
    "### Running a RAG Pipeline with Morpheus\n",
    "\n",
    "How do we utilize the Vector Database to answer questions?\n",
    "\n",
    "#### Morpheus Overview\n",
    "\n",
    "Quick overview of what Morpheus is and how to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3833deda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to run a Morpheus pipeline using the vector database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4b8a57",
   "metadata": {},
   "source": [
    "### Hitting the Limits of the LLMs\n",
    "\n",
    "This section will go over some of the areas where LLMs may fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7e791c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example to cause the LLM to fail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8c30da",
   "metadata": {},
   "source": [
    "## Part 3 - Beyond Prototyping\n",
    "\n",
    "This section will focus on refining the prototype to fix any gaps, improve the accuracy, and create a production ready pipeline.\n",
    "\n",
    "### Improving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91ef4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for improving the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a826b5",
   "metadata": {},
   "source": [
    "### Batching Multiple Requests\n",
    "\n",
    "This section will show how to run multiple requests simultaneously improving the throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895f9bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for batching multiple requets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66334a9",
   "metadata": {},
   "source": [
    "### Creating a Microservice\n",
    "\n",
    "This section will show how to convert the development pipeline into a microservice which is capable of handling requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8d4182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for creating a microservice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec9cbc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from morpheus.config import Config, PipelineModes\n",
    "\n",
    "# Create the pipeline config\n",
    "pipeline_config = Config()\n",
    "pipeline_config.mode = PipelineModes.OTHER\n",
    "\n",
    "# Below properties are specified by the command line\n",
    "# pipeline_config.num_threads = num_threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b628e418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"checklist\": {\n",
      "    \"model\": {\n",
      "      \"service\": {\n",
      "        \"type\": \"nemo\",\n",
      "        \"api_key\": null,\n",
      "        \"org_id\": null\n",
      "      },\n",
      "      \"model_name\": \"gpt-43b-002\",\n",
      "      \"customization_id\": null,\n",
      "      \"temperature\": 0.0,\n",
      "      \"tokens_to_generate\": 300\n",
      "    }\n",
      "  },\n",
      "  \"agent\": {\n",
      "    \"model\": {\n",
      "      \"service\": {\n",
      "        \"type\": \"nvfoundation\",\n",
      "        \"api_key\": null\n",
      "      },\n",
      "      \"model_name\": \"mixtral_8x7b\",\n",
      "      \"temperature\": 0.0\n",
      "    },\n",
      "    \"sbom\": {\n",
      "      \"data_file\": \"\"\n",
      "    },\n",
      "    \"code_repo\": {\n",
      "      \"faiss_dir\": \"/home/mdemoret/Repos/morpheus/morpheus-dev2/.tmp/Sherlock/NSPECT-V1TL-NPZI_code_faiss\",\n",
      "      \"embedding_model_name\": \"Xenova/text-embedding-ada-002\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from cyber_dev_day.config import EngineConfig\n",
    "\n",
    "# Create the engine configuration\n",
    "engine_config = EngineConfig.model_validate({\n",
    "    'checklist': {\n",
    "        'model': {\n",
    "            'service': {\n",
    "                'type': 'nemo', 'api_key': None, 'org_id': None\n",
    "            },\n",
    "            'model_name': 'gpt-43b-002',\n",
    "            'customization_id': None,\n",
    "            'temperature': 0.0,\n",
    "            'tokens_to_generate': 300\n",
    "        }\n",
    "    },\n",
    "    'agent': {\n",
    "        'model': {\n",
    "            'service': {\n",
    "                'type': 'nvfoundation', 'api_key': None\n",
    "            }, 'model_name': 'mixtral_8x7b', 'temperature': 0.0\n",
    "        },\n",
    "        'sbom': {\n",
    "            'data_file': ''\n",
    "        },\n",
    "        'code_repo': {\n",
    "            'faiss_dir': f'{os.getenv(\"MORPHEUS_ROOT\")}/.tmp/Sherlock/NSPECT-V1TL-NPZI_code_faiss',\n",
    "            'embedding_model_name': 'Xenova/text-embedding-ada-002'\n",
    "        }\n",
    "    }\n",
    "})\n",
    "\n",
    "print(engine_config.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a16bf979",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I20240308 15:31:12.977725 2962942 asyncio_runnable.hpp:246] AsyncioRunnable::run() > Creating new event loop\n",
      "I20240308 15:31:13.021863 2962942 asyncio_runnable.hpp:259] AsyncioRunnable::run() > Calling run_until_complete() on main_task()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to check if the Docker container's Linux kernel has the mentioned use-after-free vulnerability in the specified file and function. To do this, I can first use the SBOM Package Checker to see if the Linux kernel is present in the container and get its version number. Then, I can use the Docker Container Code QA System to check if the container's Linux kernel uses the problematic function in the given file.\n",
      "\n",
      "Action: SBOM Package Checker\n",
      "Action Input: Linux kernel\n",
      "\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mFalse\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe SBOM Package Checker did not find the Linux kernel in the Docker container, which means the container might not be using its own kernel but rather the host's kernel. In this case, I cannot provide a definitive answer based solely on the container's SBOM. However, if the container is using the host's kernel, I can still attempt to check for the vulnerability using the Docker Container Code QA System.\n",
      "\n",
      "Action: Docker Container Code QA System\n",
      "Action Input: drivers/media/dvb-core/dvbdev.c has a use-after-free, related to dvb_register_device dynamically allocating fops.\n",
      "\n",
      "\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mBased on the given context, it seems that there are multiple instances of `dfp_monitor_module` and `dfp_post_proc_module`. If `dvb_register_device` is dynamically allocating `fops` for these modules and there is a use-after-free vulnerability in `drivers/media/dvb-core/dvbdev.c`, then it is possible that the freed `fops` are being accessed or used after they have been deallocated. This could lead to unpredictable behavior, memory corruption, or even a system crash.\n",
      "\n",
      "It is important to properly manage the lifetime of these `fops` objects and ensure that they are not accessed after they have been freed. This could involve checking for null pointers, using reference counting, or implementing some other form of memory management to prevent use-after-free vulnerabilities.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "\n",
      "Final Answer: Based on the information provided, it appears that the Docker container may be using a version of the Linux kernel that is affected by a use-after-free vulnerability in the `dvb_register_device` function of the `drivers/media/dvb-core/dvbdev.c` file. However, the SBOM Package Checker did not find the Linux kernel in the Docker container, which suggests that the container might be using the host's kernel instead.\n",
      "\n",
      "The Docker Container Code QA System found potential instances of use-after-free vulnerabilities in the `dfp_monitor_module` and `dfp_post_proc_module` modules. If `dvb_register_device` is dynamically allocating `fops` for these modules and there is a use-after-free vulnerability in `drivers/media/dvb-core/dvbdev.c`, then it is possible that the freed `fops` are being accessed or used after they have been deallocated. This could lead to unpredictable behavior, memory corruption, or even a system crash.\n",
      "\n",
      "To mitigate this vulnerability, it is important to properly manage the lifetime of these `fops` objects and ensure that they are not accessed after they have been freed. This could involve checking for null pointers, using reference counting, or implementing some other form of memory management to prevent use-after-free vulnerabilities.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Pipeline complete. Received 1 responses:\n",
      "\"\"\n",
      "0    Based on the information provided, it appears ...\n",
      "Name: response, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import cudf\n",
    "from cyber_dev_day.pipeline_utils import build_llm_engine\n",
    "from morpheus.messages import ControlMessage\n",
    "from morpheus.pipeline.linear_pipeline import LinearPipeline\n",
    "from morpheus.stages.input.in_memory_source_stage import InMemorySourceStage\n",
    "from morpheus.stages.llm.llm_engine_stage import LLMEngineStage\n",
    "from morpheus.stages.output.in_memory_sink_stage import InMemorySinkStage\n",
    "from morpheus.stages.preprocess.deserialize_stage import DeserializeStage\n",
    "from morpheus.utils.concat_df import concat_dataframes\n",
    "\n",
    "source_dfs = [\n",
    "    cudf.DataFrame({\n",
    "        \"cve_info\": [\n",
    "            \"An issue was discovered in the Linux kernel through 6.0.9. drivers/media/dvb-core/dvbdev.c has a use-after-free, related to dvb_register_device dynamically allocating fops.\"\n",
    "        ]\n",
    "    })\n",
    "]\n",
    "\n",
    "completion_task = {\"task_type\": \"completion\", \"task_dict\": {\"input_keys\": [\"cve_info\"], }}\n",
    "\n",
    "pipe = LinearPipeline(pipeline_config)\n",
    "\n",
    "pipe.set_source(InMemorySourceStage(pipeline_config, dataframes=source_dfs))\n",
    "\n",
    "pipe.add_stage(DeserializeStage(pipeline_config, message_type=ControlMessage, task_type=\"llm_engine\", task_payload=completion_task))\n",
    "\n",
    "pipe.add_stage(LLMEngineStage(pipeline_config, engine=build_llm_engine(engine_config)))\n",
    "\n",
    "sink = pipe.add_stage(InMemorySinkStage(pipeline_config))\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "await pipe.run_async()\n",
    "\n",
    "messages = sink.get_messages()\n",
    "responses = concat_dataframes(messages)\n",
    "\n",
    "logger.info(\"Pipeline complete\")\n",
    "\n",
    "print(\"Pipeline complete. Received %s responses:\\n%s\" % (len(messages), responses['response']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f87ac9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
