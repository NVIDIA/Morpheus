{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2941e94f-db20-44a5-ab87-2cab499825f7",
   "metadata": {},
   "source": [
    "# Cyber Developer Day 2024\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Generative AI (GenAI) and Large Language Models (LLMs) are becoming essential tools in cybersecurity in part due to their ability to enhance the efficiency of cyber threat detection and response by accelerating analyst workflows. Prototyping and moving theses accelerated workflows into production can be daunting\n",
    "Cybersecurity remains among the top three challenges impacting every industryâ€”from the public sector to financial services, telecommunications, retail, automotive, and more. Most CEOs believe organizations with the most advanced generative AI capabilities will have a competitive advantage and are looking for ways to incorporate this into their business. Adversaries are already using generative AI in their attacks, however, and much more can be done to harness this power for cyberdefense. This hands-on tutorial will focus on accelerating an exploitablity analysis workflow to increase analyst productivity and enhance cybersecurity defenses.\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "Determining the impact of a documented Common Vulnerabilities and Exposures (CVE) on a specific project or container is a labor-intensive and manual task. This process involves the collection, comprehension, and synthesis of various pieces of information to ascertain whether immediate remediation, such as patching, is necessary upon the identification of a new CVE. Often, reasons cited for not updating a library affected by a CVE include the occurrence of scan false positives, the existence of mitigating factors, or the absence of necessary environments or dependencies for the exploit to be viable. Once an analyst has determined the library is not affected, a Vulnerability Exploitability eXchange (VEX) document must be created to standardize and distribute the results. The efficiency of this process can be significantly enhanced through the deployment of an event-driven LLM agent pipeline.\n",
    "\n",
    "### Tutorial Goals\n",
    "\n",
    "Our team developed a cybersecurity vulnerability analysis tool to aid in assessing the exploitability of CVEs in specific projects and containers. The following tutorial shows step-by-step how to leverage LLMs, RAG, and agents to create toy version and microservice running LLM-powered CVE exploitability analysis.\n",
    "Students can experiment with the different modules to expand on this use case or leverage these modular pieces to construct a new pipeline of their own.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "- [0 - Environment Setup](#0---Environment-Setup)\n",
    "- [1 - Intro to Interacting with LLMs](#1---Intro-to-Interacting-with-LLMs)\n",
    "  - [1.1 - Python Calls to LLM API](#1.1---Python-Calls-to-LLM-API)\n",
    "  - [1.2 - Prompt Engineering](#1.2---Prompt-Engineering)\n",
    "  - [1.3 - Prompt Templating](#1.3---Prompt-Templating)\n",
    "  - [1.4 - One-Shot Learning](#1.4---One-Shot-Learning)\n",
    "  - [1.5 - Few-Shot Learning](#1.5---Few-Shot-Learning)\n",
    "  - [1.6 - Evaluation Strategies](#1.6---Evaluation-Strategies)\n",
    "- [2 - Prototyping](#2---Prototyping)\n",
    "  - [2.1 - Overview](#21---overview)\n",
    "  - [2.2 - Building the Vector Database](#22---building-the-vector-database)\n",
    "  - [2.3 - Running a RAG pipeline with Morpheus](#23---running-a-rag-pipeline-with-morpheus)\n",
    "  - [2.4 - Running the CVE Pipeline with Morpheus](#24---running-the-cve-pipeline-with-morpheus)\n",
    "- [3 - Beyond Prototyping](#3---Beyond-Prototyping)\n",
    "  - [3.1 - Improving the Model](#31---improving-the-model)\n",
    "  - [3.2 - Scaling the Pipeline](#32---scaling-the-pipeline)\n",
    "  - [3.3 - Event Driven Pipeline: Creating a Microservice](#33---event-driven-pipeline-creating-a-microservice)\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> Please continue running the notebook up to Part 1 during the introduction presentation to ensure your environment is set up correctly.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1392801d-3325-4297-974a-e430f5248170",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff405752-d264-49b4-946f-ccb693ccb732",
   "metadata": {},
   "source": [
    "## 0 - Environment Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4700a3a1",
   "metadata": {},
   "source": [
    "The following code blocks are used to setup environment variables and imports for the rest of the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a60d2a30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%aimport -logging\n",
    "%autoreload 2\n",
    "\n",
    "# Ensure that the morpheus directory is in the python path. This may not need to be run depending on the environment setup\n",
    "import sys\n",
    "import os\n",
    "\n",
    "if (\"MORPHEUS_ROOT\" not in os.environ):\n",
    "    os.environ[\"MORPHEUS_ROOT\"] = os.path.abspath(\"../../..\")\n",
    "\n",
    "llm_dir = os.path.abspath(os.path.join(os.getenv(\"MORPHEUS_ROOT\", \"../../..\"), \"examples\", \"cyber_dev_day\"))\n",
    "\n",
    "if (llm_dir not in sys.path):\n",
    "    sys.path.append(llm_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3523bc32",
   "metadata": {},
   "source": [
    "Ensure the necessary environment variables are set. As a last resort, try to load them from a `.env` file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef295094",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ensure that the current environment is set up with API keys\n",
    "required_env_vars = [\n",
    "    \"MORPHEUS_ROOT\",\n",
    "    \"NGC_API_KEY\",\n",
    "    \"NVIDIA_API_KEY\",\n",
    "]\n",
    "\n",
    "if (not all([var in os.environ for var in required_env_vars])):\n",
    "\n",
    "    # Try loading an .env file if it exists\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "\n",
    "    # Check again\n",
    "    if (not all([var in os.environ for var in required_env_vars])):\n",
    "        raise ValueError(f\"Please set the following environment variables: {required_env_vars}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86203ec2",
   "metadata": {},
   "source": [
    "Import some common libraries to allow them to be used later in the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2aa2691",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import time\n",
    "from textwrap import wrap\n",
    "\n",
    "import pandas as pd\n",
    "from nemollm.api import NemoLLM\n",
    "\n",
    "import cudf\n",
    "\n",
    "# Finally, ensure Morpheus is installed correctly\n",
    "import morpheus._lib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7932f728",
   "metadata": {},
   "source": [
    "Configure logging to allow Morpheus messages to appear in the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9ab76ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "import cyber_dev_day\n",
    "\n",
    "# Create a logger for this module. Use the cyber_dev_day module name because the notebook will just be __main__\n",
    "logger = logging.getLogger(cyber_dev_day.__name__)\n",
    "\n",
    "# Configure the parent logger log level\n",
    "logger.parent.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfc3ce8",
   "metadata": {},
   "source": [
    "Finally, test out the logger to ensure that it is working correctly. You should see a message printed to the console.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78a1fcfd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully configured logging!\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Successfully configured logging!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b911e7b9-18bd-4972-a7e1-ff1c976ba66b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> Please wait here until instructed to continue with running Part 1 of the notebook.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb62b83",
   "metadata": {},
   "source": [
    "## 1 - Intro to Interacting with LLMs\n",
    "\n",
    "This section will go over how to integrate LLMs into code with Python based examples. We will highlight some of the basic techniques for using and improving calls to LLMs for cybersecurity use cases.\n",
    "\n",
    "1. Python calls to LLM API\n",
    "2. Prompt engineering\n",
    "3. Prompt templating\n",
    "4. One-shot learning\n",
    "5. Multi-shot learning\n",
    "\n",
    "In this lab, we will be using [NVIDIA NeMo](https://www.nvidia.com/en-us/ai-data-science/generative-ai/nemo-framework/) as our generative AI platform. NeMo is a cloud-native framework for building, customizing and deploying generative AI models with a familiar ChatGPT-like interface. Utilizing NeMo (or any other generative AI service) in our pipelines allows us to offload the heavy lifting of language model inference to a dedicated service, freeing up our own resources for other tasks. All requests to the NeMo service are made via an HTTP API, which allows us to easily integrate it into our existing codebase.\n",
    "\n",
    "To simplify the process of interacting with the NeMo service, the NeMo team provides a Python client library (`nemollm`) that wraps the HTTP API. This library provides a simple interface for making requests to the NeMo service, and handles the details of making HTTP requests and parsing the responses. This allows us to focus on the high-level logic of our application, rather than the low-level details of making HTTP requests.\n",
    "\n",
    "Before sending requests to the NeMo service, we need to set up a NeMo connection object, `conn` which is shown below. We will use the `generate()` method of the connection object to send requests to the NeMo service for the remainder of this section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67c8c1d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the connection object. The API key and organization ID are read from the environment variables NGC_API_KEY and\n",
    "# NGC_ORG_ID respectively\n",
    "conn = NemoLLM(api_host=os.getenv(\"NGC_API_BASE\", None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4639ba36-02ac-4a94-9815-182bbda12c38",
   "metadata": {},
   "source": [
    "### 1.1 - Python Calls to LLM API\n",
    "\n",
    "<dl>\n",
    "<dt><b>Use Case</b></dt>\n",
    "<dd>General cyber knowledge assistant, productivity tool to aid cyber analysts.</dd>\n",
    "<dt><b>Query</b></dt>\n",
    "<dd><code>In general, how can I determine if my specific environment is affected by a CVE?</code></dd>\n",
    "</dl>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "739e8a57-d198-4f6b-911b-0500f97a983d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The best way to determine if your specific environment is affected by a CVE is to check the CVE entry for the vulnerability. The CVE entry will contain information about the vulnerability, including its severity, affected versions, and any available patches or mitigations. You can search for the CVE on the CVE List website, which is maintained by the MITRE Corporation.\\n\\nIf you are unable to find information about the vulnerability on the CVE List website, you can also check the websites of the vendors who provide the software or hardware that you are using. Vendors often release information about vulnerabilities that affect their products, including whether a patch or mitigation is available.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.generate(\n",
    "    prompt=\"In general, how can I determine if my specific environment is affected by a CVE?\",\n",
    "    model=\"gpt-43b-002\",\n",
    "    tokens_to_generate=128,\n",
    "    temperature=0,\n",
    "    top_k=1,\n",
    "    return_type=\"text\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21d4222-9f6d-46cf-b037-b765889825cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1.1.1 - Explore On Your Own: Different Models\n",
    "\n",
    "Try another model such as `gpt-8b-000` `gpt20b` or `llama-2-70b-hf`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70ef49a4-df05-4f68-8cd8-7eb053e31397",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nI'm trying to determine if my specific environment is affected by a CVE.\\nI'm not sure if I'm asking the right question, but I'm trying to determine if my specific environment is affected by a CVE.\\nI'm not sure if I'm asking the right question, but I'm trying to determine if my specific environment is affected by a CVE. I'm not sure if I'm asking the right question, but I'm trying to determine if my specific environment is affected by a CVE.\\nI'm not sure if I'm asking the\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Do we remove the filled out section here?\n",
    "conn.generate(\n",
    "    prompt=\"In general, how can I determine if my specific environment is affected by a CVE?\",\n",
    "    model=\"llama-2-70b-hf\",\n",
    "    tokens_to_generate=128,\n",
    "    temperature=0,\n",
    "    return_type=\"text\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffff783-1e41-46cb-a819-e9fb96252d31",
   "metadata": {},
   "source": [
    "#### 1.1.2 - Explore On Your Own: Model Parameters\n",
    "\n",
    "How do the different models compare? Can you change the parameters (like `temperature` or `repetition_penalty`) to help the smaller models improve?\n",
    "\n",
    "What are some other cybersecurity questions you could ask an LLM to upskill a junior analyst?\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ea77bf-4595-493c-a119-0a249502252b",
   "metadata": {},
   "source": [
    "Try few temperature values `temperature=[0.0, 0.5, 0.7, 0.9]` and higher value of `1<top_k<64` such as `[2, 10, 30]` parameter to make the model creative with its response. Higher values of the `top_k` enables the model to sample from next `k` probable token. If `top_k=1`, greedy sampling is used, what happen to model output with change in `temp`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae20ccb9-f315-4d14-beb1-4e91cfc993dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # UNCOMMENT to try different parameters\n",
    "# # Analyze output of the model for different value of temperature and top_k\n",
    "# for temp in [0.0, 0.5, 0.7, 0.9]:\n",
    "#     print(conn.generate(\n",
    "#     prompt=\"In general, how can I determine if my specific environment is affected by a CVE?\",\n",
    "#     model=\"gpt-43b-002\",\n",
    "#     tokens_to_generate=100,\n",
    "#     temperature=temp,\n",
    "#     return_type=\"text\",\n",
    "#     top_k=10\n",
    "#     ))\n",
    "#     print(\"----\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb99b0a8-29e8-4b6f-94ee-dfddfe4e27cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a03af5d2-0931-4e0c-a27a-d280c9f77fcb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.2 - Prompt Engineering\n",
    "\n",
    "Some tips for improving performance using prompt engineering can be found here https://www.promptingguide.ai/introduction/tips.\n",
    "\n",
    "<dl>\n",
    "<dt><b>Use Case</b></dt>\n",
    "<dd>General cyber knowledge assistant, productivity tool to aid cyber analysts.</dd>\n",
    "<dt><b>Persona</b></dt>\n",
    "<dd>You are a helpful cybersecurity analyst with an IQ of 140.</dd>\n",
    "<dt><b>Query</b></dt>\n",
    "<dd><code>In general, how can I determine if my specific environment is vulnerable to a CVE?</code></dd>\n",
    "</dl>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95010654-9f3e-4cb1-bb31-d4ceb288c9da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" The first step in determining if your specific environment is vulnerable to a CVE is to identify the affected software or system. Once you have identified the affected software or system, you can then check the vendor's website or security bulletin to see if a patch or update is available. If a patch or update is available, you should install it as soon as possible to mitigate the vulnerability.\\n\\nIf a patch or update is not available, you can try to determine if your specific environment is vulnerable by using a tool such as Nessus or OpenVAS to scan your network for the presence of the vulnerability. If the tool detects the vulnerability, you should take immediate action to mitigate it.\\n\\nIt's important to note that even if a vulnerability is not present in your specific environment, it may still be present in other environments that are connected to yours, such as third-party services or suppliers. Therefore, it's important to keep up to date with the latest security news and advisories to ensure that you are aware of any new vulnerabilities that may affect your environment.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_prompt = \"{persona} {query}\".format(\n",
    "    persona=\"You are helpful cybersecurity expert with an IQ of 140.\",\n",
    "    query=\"In general, how can I determine if my specific environment is vulnerable to a CVE?\")\n",
    "\n",
    "conn.generate(\n",
    "    prompt=formatted_prompt,\n",
    "    model=\"gpt-43b-002\",\n",
    "    tokens_to_generate=256,\n",
    "    temperature=0,\n",
    "    return_type=\"text\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1035ba69-8a51-4d92-950f-d1b4e420cd70",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### _Explore on your own_\n",
    "\n",
    "##### Does the persona improve performance?\n",
    "\n",
    "##### What happens if you change the persona or attributes such as IQ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b28a67d-c426-42a7-9656-16461ec5f58e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Try to change the content of persona and rerun the above code. \n",
    "# E.g. \n",
    "# persona = \"You are helpful cybersecurity expert with an IQ of 40.\",\n",
    "# persona = \"You are helpful data analyst with experience in analyzing vulnerabilites\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c485395e-38b7-4c63-ad62-7dcacd5b9757",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b265febf-5117-4010-a879-dc41ab957c5d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.3 - Prompt Templating\n",
    "\n",
    "including prompt template to include specific CVE context for the model\n",
    "\n",
    "Can our LLM help with specific CVEs?\n",
    "\n",
    "`Query: \"How can I determine if my specific environment is affected by CVE-2023-47248?`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8923b1fa-1a41-4fb6-83f3-dacca4bc9316",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" I'm sorry, but as a language model AI, I cannot access real-time information about specific cybersecurity threats. However, I can provide you with general guidance on how to stay safe online. Here are some tips:\\n\\n1. Keep your software and operating system up to date with the latest security patches.\\n2. Use strong and unique passwords for each account, and consider using a password manager.\\n3. Enable two-factor authentication (2FA) wherever possible.\\n4. Be cautious of suspicious emails, texts, and phone calls, and never click on links or download attachments from unknown sources.\\n5. Regularly back up your important data to an external drive or cloud storage service.\\n6. Install and regularly update antivirus and anti-malware software on your devices.\\n7. Be aware of phishing scams, which attempt to trick you into providing sensitive information or downloading malware.\\n\\nBy following these general security measures, you can help protect yourself from a wide range of cyber threats, including CVE-2023-47248. However, it's important to keep in mind that no security measure is foolproof, and you should always be vigilant about protecting your personal information and data.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_prompt = \"{persona} {query}\".format(\n",
    "    persona=\"You are helpful cybersecurity expert with an IQ of 140.\",\n",
    "    query=\"How can I determine if my specific environment is affected by CVE-2023-47248?\")\n",
    "\n",
    "conn.generate(\n",
    "    prompt=formatted_prompt,\n",
    "    model=\"gpt-43b-002\",\n",
    "    tokens_to_generate=256,\n",
    "    temperature=0,\n",
    "    return_type=\"text\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f374c4a4-67b1-4dad-92c8-ca74995af35c",
   "metadata": {},
   "source": [
    "##### What are some methods to get up-to-date CVE knowledge to our model?\n",
    "\n",
    "##### Can we add it to the prompt?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be6dcba4-4e4b-4dd4-8c46-5eb7f767385b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Check if the containerized environment uses PyArrow 0.14.0 through 14.0.1.\n",
      "- If yes, check if the containerized environment reads Arrow IPC, Feather, or Parquet data from untrusted sources.\n",
      "- If yes, check if the containerized environment upgrades to PyArrow 14.0.1.\n",
      "- If no, check if the containerized environment downgrades to PyArrow 14.0.1 or later.\n",
      "- If no, check if the containerized environment uses the pyarrow-hotfix package to disable the vulnerability.\n"
     ]
    }
   ],
   "source": [
    "prompt_template = \"\"\"Generate a checklist for a security analyst to use when assessing the exploitability of a specific CVE within a containerized environment. \\\n",
    "For each checklist item, start with an action verb, making it clear and actionable. Provide the checklist as a Python list of strings. \\\n",
    "Utilize the provided CVE details below to tailor the checklist items specifically for this CVE.\n",
    "CVE Details:\n",
    "- CVE ID: {cve}\n",
    "- Description: {cve_description}\n",
    "- Vulnerable Package Name: {vuln_package}\n",
    "- Vulnerable Package Version: {vuln_package_version}\n",
    "- CVSS3 Vector String: {cvss3}\"\"\"\n",
    "\n",
    "PYARROW_CVE_INTEL = dict(\n",
    "    cve=\"CVE-2023-47248\",\n",
    "    cve_description=\"Deserialization of untrusted data in IPC and Parquet readers in PyArrow versions 0.14.0 to 14.0.0 \"\n",
    "    \"allows arbitrary code execution. An application is vulnerable if it reads Arrow IPC, Feather or Parquet data from untrusted sources \"\n",
    "    \"(for example user-supplied input files). This vulnerability only affects PyArrow, not other Apache Arrow implementations or bindings. \"\n",
    "    \"It is recommended that users of PyArrow upgrade to 14.0.1. Similarly, it is recommended that downstream libraries upgrade their dependency \"\n",
    "    \"requirements to PyArrow 14.0.1 or later. PyPI packages are already available, and we hope that conda-forge packages will be available soon. \"\n",
    "    \"If it is not possible to upgrade, we provide a separate package `pyarrow-hotfix` that disables the vulnerability on older PyArrow versions. \"\n",
    "    \"See https://pypi.org/project/pyarrow-hotfix/ for instructions.\",\n",
    "    vuln_package=\"PyArrow\",\n",
    "    vuln_package_version=\"0.14.0 through 14.0.1\",\n",
    "    cvss3=\"CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H\")\n",
    "\n",
    "formatted_prompt = prompt_template.format(**PYARROW_CVE_INTEL)\n",
    "\n",
    "print(\n",
    "    conn.generate(\n",
    "        prompt=formatted_prompt,\n",
    "        model=\"gpt-43b-002\",\n",
    "        tokens_to_generate=256,\n",
    "        temperature=0,\n",
    "        return_type=\"text\",\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6224e8-a506-406b-8d16-e9300f158fdb",
   "metadata": {},
   "source": [
    "##### Is this a useful planning step and thought process?\n",
    "\n",
    "##### Did the model generate the checklist/task list as a python list of strings as we requested?\n",
    "\n",
    "##### Do other models work better?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57d6751c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: gpt5b\n",
      "\n",
      "- CVSS3 Base Score: 7.8\n",
      "- CVSS3 Vector: (AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)\n",
      "- CVSS3 Severity: High\n",
      "- CVSS3 Vector: (AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)\n",
      "- CVSS3 Base Score: 7.8\n",
      "- CVSS3 Vector: (AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)\n",
      "- CVSS3 Severity: High\n",
      "- CVSS3 Vector: (AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)\n",
      "- CVSS3 Base Score: 7.8\n",
      "- CVSS3 Vector: (AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)\n",
      "- CVSS3\n",
      "\n",
      "\n",
      "Model: gpt-8b-000\n",
      "\n",
      "- CVSS3 Vector String: CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H\n",
      "- CVSS3 Vector String: CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H\n",
      "- CVSS3 Vector String: CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H\n",
      "- CVSS3 Vector String: CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H\n",
      "- CVSS3 Vector String: CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H\n",
      "- CVSS3 Vector String: CVSS:3.1/AV:N/AC:L/PR:N\n",
      "\n",
      "\n",
      "Model: gpt20b\n",
      "\n",
      "- CVSS3 Base Score: 7.5\n",
      "- CVSS3 Temporal Score: 7.5\n",
      "- CVSS3 Exploitability Score: 7.5\n",
      "- CVSS3 Impact Score: 7.5\n",
      "- CVSS3 Confidence Interval: 7.5\n",
      "- CVSS3 Base Vector: AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H\n",
      "- CVSS3 Temporal Vector: AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H\n",
      "- CVSS3 Exploitability Vector: AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H\n",
      "- CVSS3 Impact Vector: AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H\n",
      "- CVSS3 Confidence Vector: AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/\n",
      "\n",
      "\n",
      "Model: gpt-43b-002\n",
      " - Check if the containerized environment uses PyArrow 0.14.0 through 14.0.1.\n",
      "- If yes, check if the containerized environment reads Arrow IPC, Feather, or Parquet data from untrusted sources.\n",
      "- If yes, check if the containerized environment upgrades to PyArrow 14.0.1.\n",
      "- If no, check if the containerized environment downgrades to PyArrow 14.0.1 or later.\n",
      "- If no, check if the containerized environment uses the pyarrow-hotfix package to disable the vulnerability.\n",
      "\n",
      "\n",
      "Model: llama-2-70b-hf\n",
      "\n",
      "- CVSS3 Score: 7.5\n",
      "- CVSS3 Vector: AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H\n",
      "- CVSS3 Vector Name: CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H\n",
      "- CVSS3 Vector Description: CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H\n",
      "- CVSS3 Vector Description: CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H\n",
      "- CVSS3 Vector Description: CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H\n",
      "- CVSS3 Vector Description: CVSS:3.1/AV:N/AC:L\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models_to_try = ['gpt5b', 'gpt-8b-000', 'gpt20b', 'gpt-43b-002', 'llama-2-70b-hf']\n",
    "\n",
    "for model in models_to_try:\n",
    "    model_output = conn.generate(\n",
    "        prompt=formatted_prompt,\n",
    "        model=model,\n",
    "        tokens_to_generate=256,\n",
    "        temperature=0,\n",
    "        top_k=1,\n",
    "        return_type=\"text\",\n",
    "    )\n",
    "    print(f\"Model: {model}\\n{model_output}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0eda5da",
   "metadata": {},
   "source": [
    "##### How can we check the model's accuracy?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38fb9fc6-2137-4b93-9fdd-80b9759549c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "\n",
    "# we can evaulate if the checklist is properly formatted using this function\n",
    "def is_properly_formatted_list(checklist):\n",
    "    try:\n",
    "        # Attempt to evaluate checklist as a Python literal\n",
    "        evaluated_checklist = ast.literal_eval(checklist)\n",
    "\n",
    "        # Check if the evaluated object is a list\n",
    "        if isinstance(evaluated_checklist, list):\n",
    "            print(\"Checklist is properly formatted.\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"Checklist is not a list.\")\n",
    "            return False\n",
    "    except ValueError as e:\n",
    "        # Handle the case where checklist cannot be evaluated as a Python literal\n",
    "        print(f\"Checklist is not properly formatted: {e}\")\n",
    "        return False\n",
    "    except SyntaxError as e:\n",
    "        # Handle syntax errors in the checklist string\n",
    "        print(f\"Checklist has a syntax error: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e3f10a1-f446-4987-a1d1-7daf69c46a84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checklist has a syntax error: expected 'else' after 'if' expression (<unknown>, line 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_properly_formatted_list(\n",
    "    conn.generate(\n",
    "        prompt=formatted_prompt,\n",
    "        model=\"gpt-43b-002\",\n",
    "        tokens_to_generate=256,\n",
    "        temperature=0,\n",
    "        return_type=\"text\",\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026b10cf-994e-4ed8-8414-86ecd820708d",
   "metadata": {},
   "source": [
    "##### How can we improve performance?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2e48eb-073f-4984-a398-9b5f118391a2",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### 1.4 - One-Shot Learning\n",
    "\n",
    "Adding an example into the prompt can improve results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e49717a-6e08-44dd-b87d-cb26091a64fd",
   "metadata": {},
   "source": [
    "You are an expert secuirty analyst. Your objective is to add a \"Checklist\" section containing steps to use when assessing the exploitability of a specific CVE within a containerized environment. \\\n",
    "For each checklist item, start with an action verb, making it clear and actionable\n",
    "\n",
    "**Context**:\n",
    "Not all CVEs are exploitable in a given container. By making a checklist specific to the information available for a given CVE analysts can execute the checklist to determine exploitability.\n",
    "\n",
    "**Example Format**:\n",
    "Below is a format for examples that illustrate transforming CVE information into an exploitability assessment checklist.\n",
    "\n",
    "Example CVE Details:\n",
    "\n",
    "- CVE ID: CVE-2022-2309\n",
    "- Description: NULL Pointer Dereference allows attackers to cause a denial of service (or application crash). This only applies when lxml up to version 4.9.1 \\\n",
    "  is used together with libxml2 2.9.10 through 2.9.14. libxml2 2.9.9 and earlier are not affected. It allows triggering crashes through forged input data, given a\n",
    "  vulnerable code sequence in the application. The vulnerability is caused by the iterwalk function (also used by the canonicalize function). Such code shouldn't be\n",
    "  in wide-spread use, given that parsing + iterwalk would usually be replaced with the more efficient iterparse function. However, an XML converter that serialises to \\\n",
    "  C14N would also be vulnerable, for example, and there are legitimate use cases for this code sequence. If untrusted input is received (also remotely) and processed via \\\n",
    "  iterwalk function, a crash can be triggered.\n",
    "- Vulnerable Package Name: lxml, libxml2\n",
    "- Vulnerable Package Version: lxml: up to 4.9.1, libxml2: 2.91.0 through 2.9.14\n",
    "- CVSS3 Vector String: CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H\n",
    "\n",
    "Example Exploitability Assessment Checklist: \\\n",
    "[\n",
    "\"Check for lxml: Verify if your project uses the lxml library, which is the affected package. If lxml is not a dependency in your project, then your code is not vulnerable to this CVE.\",\n",
    "\"Review Affected Versions: If lxml is used, checked the version that your project depends on. According to the vulnerability details, versions 4.9.0 and earlier are vulnerable.\",\n",
    "\"Review Versions of Connected Dependencies: The package is only vulnerable if libxml 2.9.10 through 2.9.14 is also present. Check the version of libxml in the project.\",\n",
    "\"Check for use of vulnerable functions: The library is vulnerable through its `iterwalk` function, which is also utilized by the `canonicalize` function. Check if either of these functions are used in your code base.\"\n",
    "]\n",
    "\n",
    "**Criteria**:\n",
    "\n",
    "- Exploitability assessment checklists must relate to the information in the specific CVE Details.\n",
    "\n",
    "**Procedure**:\n",
    "[\n",
    "\"Understand the CVE Details, description, and CVSS3 attack vector string.\",\n",
    "\"Produce a CVE exploitability assessment checklist.\",\n",
    "\"Format the checklist as comma separated list surrounded by square braces.\",\n",
    "\"Output the checklist.\"\n",
    "]\n",
    "\n",
    "**CVE Details:**\n",
    "\n",
    "- CVE ID: {cve} \\\n",
    "- Description: {cve_description} \\\n",
    "- Vulnerable Package Name: {vuln_package} \\\n",
    "- CVSS3 Vector String: {cvss3}\"\n",
    "\n",
    "**Checklist**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "665023f4-f5a1-45cc-aeb4-e59dac16c1b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\n",
      "\"Check for PyArrow: Verify if your project uses PyArrow, which is the affected package. If PyArrow is not a dependency in your project, then your code is not vulnerable to this CVE.\",\n",
      "\"Review Affected Versions: If PyArrow is used, check the version that your project depends on. According to the vulnerability details, versions 0.14.0 through 14.0.1 are vulnerable.\",\n",
      "\"Review Versions of Connected Dependencies: The package is only vulnerable if Arrow is also present. Check the version of Arrow in the project.\",\n",
      "\"Check for use of vulnerable functions: The library is vulnerable through its IPC and Parquet readers. Check if these functions are used in your code base.\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "one_shot_prompt_template = \"\"\"You are an expert secuirty analyst. Your objective is to add a \"Checklist\" section containing steps to use when assessing the exploitability of a specific CVE within a containerized environment. \\\n",
    "For each checklist item, start with an action verb, making it clear and actionable\n",
    "\n",
    "**Context**:\n",
    "Not all CVEs are exploitable in a given container. By making a checklist specific to the information available for a given CVE analysts can execute the checklist to determine exploitability.\n",
    "\n",
    "**Example Format**:\n",
    "Below is a format for examples that illustrate transforming CVE information into an exploitability assessment checklist.\n",
    "\n",
    "Example CVE Details:\n",
    "- CVE ID: CVE-2022-2309 \\\n",
    "- Description: NULL Pointer Dereference allows attackers to cause a denial of service (or application crash). This only applies when lxml up to version 4.9.1 \\\n",
    "is used together with libxml2 2.9.10 through 2.9.14. libxml2 2.9.9 and earlier are not affected. It allows triggering crashes through forged input data, given a\n",
    "vulnerable code sequence in the application. The vulnerability is caused by the iterwalk function (also used by the canonicalize function). Such code shouldn't be\n",
    "in wide-spread use, given that parsing + iterwalk would usually be replaced with the more efficient iterparse function. However, an XML converter that serialises to \\\n",
    "C14N would also be vulnerable, for example, and there are legitimate use cases for this code sequence. If untrusted input is received (also remotely) and processed via \\\n",
    "iterwalk function, a crash can be triggered.\n",
    "- Vulnerable Package Name: lxml, libxml2\n",
    "- Vulnerable Package Version: lxml: up to 4.9.1, libxml2: 2.91.0 through 2.9.14\n",
    "- CVSS3 Vector String: CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H\n",
    "\n",
    "Example Exploitability Assessment Checklist: \\\n",
    "[\n",
    "\"Check for lxml: Verify if your project uses the lxml library, which is the affected package. If lxml is not a dependency in your project, then your code is not vulnerable to this CVE.\",\n",
    "\"Review Affected Versions: If lxml is used, checked the version that your project depends on. According to the vulnerability details, versions 4.9.0 and earlier are vulnerable.\",\n",
    "\"Review Versions of Connected Dependencies: The package is only vulnerable if libxml 2.9.10 through 2.9.14 is also present. Check the version of libxml in the project.\",\n",
    "\"Check for use of vulnerable functions: The library is vulnerable through its `iterwalk` function, which is also utilized by the `canonicalize` function. Check if either of these functions are used in your code base.\"\n",
    "]\n",
    "\n",
    "**Criteria**:\n",
    "- Exploitability assessment checklists must relate to the information in the specific CVE Details.\n",
    "\n",
    "**Procedure**:\n",
    "[\n",
    "\"Understand the CVE Details, description, and CVSS3 attack vector string.\",\n",
    "\"Produce a CVE exploitability assessment checklist.\",\n",
    "\"Format the checklist as comma separated list surrounded by square braces.\",\n",
    "\"Output the checklist.\"\n",
    "]\n",
    "\n",
    "**CVE Details:**\n",
    "- CVE ID: {cve}\n",
    "- Description: {cve_description}\n",
    "- Vulnerable Package Name: {vuln_package}\n",
    "- Vulnerable Package Version: {vuln_package_version}\n",
    "- CVSS3 Vector String: {cvss3}\"\n",
    "\n",
    "**Checklist**: \"\"\"\n",
    "\n",
    "formatted_prompt = one_shot_prompt_template.format(**PYARROW_CVE_INTEL)\n",
    "\n",
    "model_output = conn.generate(\n",
    "    prompt=formatted_prompt,\n",
    "    model=\"gpt-43b-002\",\n",
    "    tokens_to_generate=256,\n",
    "    temperature=0,\n",
    "    return_type=\"text\",\n",
    ")\n",
    "\n",
    "print(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "515f42e7-10ac-46b5-8df6-5f3d1f6d19a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checklist is properly formatted.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_properly_formatted_list(model_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ab5e62-b82e-4add-aea2-8ae58aba4c28",
   "metadata": {},
   "source": [
    "##### Do the examples and specific instructions help?\n",
    "\n",
    "##### Is there anything you would add to the PyArrow checklist?\n",
    "\n",
    "##### Would an example with a workaround or hotfix help?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca366ae-4557-4b9f-be6c-1aacb5e0c52f",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08bba90-3201-4c95-b8c4-6f4d2eb0f3a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.5 - Few-Shot Learning\n",
    "\n",
    "Including multiple diverse examples in the prompt can improve performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62834ec0-ef09-4462-88e1-851066dd45cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\n",
      "\"Check for PyArrow: Verify if your project uses the PyArrow library, which is the affected package. If PyArrow is not a dependency in your project, then your code is not vulnerable to this CVE.\",\n",
      "\"Review Affected Versions: If PyArrow is used, check the version that your project depends on. According to the vulnerability details, versions 0.14.0 through 14.0.1 are affected by this vulnerability.\",\n",
      "\"Review Code to Check for Vulnerability Mitigation: Check if the code uses the `pyarrow.ipc.read_feather` or `pyarrow.parquet.read_parquet` functions to read Arrow IPC, Feather, or Parquet data from untrusted sources. If so, consider upgrading to PyArrow 14.0.1 or later, or using the `pyarrow-hotfix` package to disable the vulnerability on older PyArrow versions.\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "few_shot_prompt_template = \"\"\"You are an expert secuirty analyst. Your objective is to add a \"Checklist\" section containing steps to use when assessing the exploitability of a specific CVE within a containerized environment. \\\n",
    "For each checklist item, start with an action verb, making it clear and actionable\n",
    "\n",
    "**Context**:\n",
    "Not all CVEs are exploitable in a given container. By making a checklist specific to the information available for a given CVE analysts can execute the checklist to determine exploitability.\n",
    "\n",
    "**Example Format**:\n",
    "Below is a format for examples that illustrate transforming CVE information into an exploitability assessment checklist.\n",
    "\n",
    "Example 1 CVE Details:\n",
    "- CVE ID: CVE-2022-2309\n",
    "- Description: NULL Pointer Dereference allows attackers to cause a denial of service (or application crash). This only applies when lxml up to version 4.9.1 \\\n",
    "is used together with libxml2 2.9.10 through 2.9.14. libxml2 2.9.9 and earlier are not affected. It allows triggering crashes through forged input data, given a\n",
    "vulnerable code sequence in the application. The vulnerability is caused by the iterwalk function (also used by the canonicalize function). Such code shouldn't be\n",
    "in wide-spread use, given that parsing + iterwalk would usually be replaced with the more efficient iterparse function. However, an XML converter that serialises to \\\n",
    "C14N would also be vulnerable, for example, and there are legitimate use cases for this code sequence. If untrusted input is received (also remotely) and processed via \\\n",
    "iterwalk function, a crash can be triggered.\n",
    "- Vulnerable Package Name: lxml, libxml2\n",
    "- Vulnerable Package Version: lxml: up to 4.9.1, libxml2: 2.91.0 through 2.9.14\n",
    "- CVSS3 Vector String: CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H\n",
    "\n",
    "Example 1 Exploitability Assessment Checklist:\n",
    "[\n",
    "\"Check for lxml: Verify if your project uses the lxml library, which is the affected package. If lxml is not a dependency in your project, then your code is not vulnerable to this CVE.\",\n",
    "\"Review Affected Versions: If lxml is used, checked the version that your project depends on. According to the vulnerability details, versions 4.9.0 and earlier are vulnerable.\",\n",
    "\"Review Versions of Connected Dependencies: The package is only vulnerable if libxml 2.9.10 through 2.9.14 is also present. Check the version of libxml in the project.\",\n",
    "\"Check for use of vulnerable functions: The library is vulnerable through its `iterwalk` function, which is also utilized by the `canonicalize` function. Check if either of these functions are used in your code base.\"\n",
    "]\n",
    "\n",
    "Example 2 CVE Details:\n",
    "- CVE ID: CVE-2024-23334\n",
    "- Description: aiohttp is an asynchronous HTTP client/server framework for asyncio and Python. When using aiohttp as a web server and configuring static routes, \\\n",
    "it is necessary to specify the root path for static files. Additionally, the option 'follow_symlinks' can be used to determine whether to follow symbolic links \\\n",
    "outside the static root directory. When 'follow_symlinks' is set to True, there is no validation to check if reading a file is within the root directory. This can \\\n",
    "lead to directory traversal vulnerabilities, resulting in unauthorized access to arbitrary files on the system, even when symlinks are not present. \\\n",
    "Disabling `follow_symlinks` by setting `follow_symlinks = False` and using a reverse proxy are encouraged mitigations. Version 3.9.2 fixes this issue.\n",
    "- Vulnerable Package Name: aiohttp\n",
    "- Vulnerable Package Version: from 1.0.5 up to (excluding) 3.9.2\n",
    "- CVSS3 Vector String: CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N\n",
    "\n",
    "Example 2 Exploitability Assessment Checklist:\n",
    "[\n",
    "    \"Check for aiohttp: Verify if your project uses the aiohttp library, which is the affected package. If aiohttp is not a dependency in your project, then your code is not vulnerable to this CVE.\",\n",
    "    \"Review Affected Versions: If aiohttp is used, check the version that your project depends on. According to the vulnerability details, versions from 1.0.5 up to (excluding) 3.9.2 are affected by this vulnerability.\",\n",
    "    \"Review Code To Check for Vulnerability Mitigation: Check if the 'follow_symlinks' option is set to False to mitigate the risk of directory traversal vulnerabilities.\"\n",
    "]\n",
    "\n",
    "**Criteria**:\n",
    "- Exploitability assessment checklists must relate to the information in the specific CVE Details.\n",
    "- Exploitability assessment checklists must include checks for mitigating conditions when present in the CVE Details.\n",
    "\n",
    "**Procedure**:\n",
    "[\n",
    "\"Understand the CVE Details, description, and CVSS3 attack vector string.\",\n",
    "\"Produce a CVE exploitability assessment checklist.\",\n",
    "\"Format the checklist as comma separated list surrounded by square braces.\",\n",
    "\"Output the checklist.\"\n",
    "]\n",
    "\n",
    "**CVE Details:**\n",
    "- CVE ID: {cve}\n",
    "- Description: {cve_description}\n",
    "- Vulnerable Package Name: {vuln_package}\n",
    "- Vulnerable Package Version: {vuln_package_version}\n",
    "- CVSS3 Vector String: {cvss3}\"\n",
    "\n",
    "**Checklist**: \"\"\"\n",
    "\n",
    "formatted_prompt = few_shot_prompt_template.format(**PYARROW_CVE_INTEL)\n",
    "\n",
    "model_output = conn.generate(\n",
    "    prompt=formatted_prompt,\n",
    "    model=\"gpt-43b-002\",\n",
    "    tokens_to_generate=256,\n",
    "    temperature=0,\n",
    "    return_type=\"text\",\n",
    "    top_k=5\n",
    ")\n",
    "\n",
    "print(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b14a3924-eb83-4ce4-91d3-e9fb7f9648b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checklist is properly formatted.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_properly_formatted_list(model_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d50410-fe09-4569-8aab-e72e4a808bc6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### _Explore on your own_\n",
    "\n",
    "##### How many examples do you think could fit in a prompt before the context is too large for the model?\n",
    "\n",
    "##### What happens when you input a tasklist item as query to the model?\n",
    "\n",
    "##### What feedback could an expert cyber analyst give you about this output?\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a804d41-01e4-4ce6-b4cc-d3e9e41fc0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check the number of examples, try to add multiple examples in the prompt.\n",
    "# Set the top_k=5, and temperature>0, and observe if you see any change in the model output.\n",
    "# formatted_prompt = few_shot_prompt_template.format(**PYARROW_CVE_INTEL)\n",
    "\n",
    "# model_output = conn.generate(\n",
    "#     prompt=formatted_prompt,\n",
    "#     model=\"gpt-43b-002\",\n",
    "#     tokens_to_generate=256,\n",
    "#     temperature=0,\n",
    "#     return_type=\"text\",\n",
    "#     top_k=5\n",
    "# )\n",
    "\n",
    "# print(model_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a7705f71-e6b3-47e4-a67d-98a57d6a0447",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# What happen if you run a tasklist item as query to the model? \n",
    "\n",
    "# task_list = ast.literal_eval(model_output)\n",
    "# for query in task_list:\n",
    "#     response = conn.generate(\n",
    "#     prompt=query,\n",
    "#     model=\"gpt-43b-002\",\n",
    "#     tokens_to_generate=256,\n",
    "#     temperature=0,\n",
    "#     return_type=\"text\")\n",
    "#     print(f\"Query: {query}\\nResponse: {response}\")\n",
    "#     print(\"\\n--------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6228cdd9-efd8-4d59-8320-c462a4a6552d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.6 - Evaluation Strategies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48198ef0-ec03-43af-a050-bfc9fa4f0ff0",
   "metadata": {},
   "source": [
    "**A Note On Evaluation Strategies**\n",
    "\n",
    "Evaluating model performance on desired metrics such as `creates a properly formatted list` is relatively straightforward and traditional accuracy measurements (ie. properly formatted outputs/total outputs) can be used.\n",
    "\n",
    "For evaluating more subjective outcomes such as `completeness of the checklist` there are other strategies that can be explored for task-specific LLMs.\n",
    "\n",
    "During this initial experimental stage it makes sense to have a expert humans review outputs to determine the model's performance. A common pattern that emerges when developing and evaluating cybersecurity use cases around LLMs is as follows:\n",
    "\n",
    "1. Experiment using a few golden examples to determine feasibility, and evaluate candidate models and prompts by hand\n",
    "2. Collect feedback on initial model outputs from experts and use this feedback to create a larger dataset\n",
    "3. Use the newly created larger dataset from experts to create a use-case specific training dataset and benchmark dataset\n",
    "\n",
    "Since getting these initial results into the hands of experts for evaluation is oftentimes a crucial component for obtaining a larger benchmark dataset, we will focus on quickly and easily building out the end-to-end pipeline for this use case example.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afdc87a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> Please wait here until instructed to continue with running the notebook.\n",
    "</div>\n",
    "\n",
    "## 2 - Prototyping\n",
    "\n",
    "Now that we have the task generation for this workflow ready, how can we automate getting the answers for our checklist items?\n",
    "\n",
    "### 2.1 - Overview\n",
    "\n",
    "It is possible to build a language model-based system that accesses external knowledge sources to complete tasks. In [Section 1.3](#1.3---Prompt-Templating), we added additional CVE details into the prompt by hand. While this strategy can be effective for adding additional context for very specific items like CVE Details, it requires apriori knowledge of what details to include (like those from NVD). When you would like to help your LLM with its query by adding more context in real-time, you're ready for RAG (Retreival Augmented Generation).\n",
    "\n",
    "When a query or checklist item is posed to an LLM equipped with RAG, the model first consults the vector database to find relevant information related to the query. This retrieved data is then combined with the original question and fed back into the LLM. With this enriched context, the LLM can generate a more accurate and informed response, potentially including evidence or reasoning based on the newly incorporated data. This approach not only improves the quality of the LLM's outputs and for our tool gives it access to project and container specific information to determine CVE exploitability.\n",
    "\n",
    "### 2.2 - Building the Vector Database\n",
    "\n",
    "In addition to having a query and LLM, RAG requires additional information to be stored in a vector database. One mechanism of finding the proper information from the database is to first embed the query into the same vector space and retreive the top most similiar items via a distance metric. The additional information is then presented in the prompt of the LLM. The neighboring vectors in the database are said to be \"semantically similiar\" to the query and likely relevant.\n",
    "\n",
    "For our demonstration purposes, we would like our LLM to be able to access the code repository of the project we're interested in checking for exploitable CVEs. The first step is transforming the specific repo into a vector database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0c5175d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f01faaf48fb043e19894999ebcbba1cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8620eca52e24734a279ca331920556c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c22640891f5c42958f90505b49f667c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c54aec927a1b488498f13b720cc35648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2630c8e8547a4d3ea8424edcc3f558a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5666059bbfba419db124571bd347fa11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dfc169161494a23a0d939f482506da4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "894edb28a2834c4da7c26201583d22e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85733f782b42414186e33971cd050156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2902976d1cde4346934a509f22e86c05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "337eebb3ada14472beb39831817f4262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4473e6ba2fcd40eab2eb8c66702c32cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from cyber_dev_day.embeddings import create_code_embedding\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Create the embedding object that will be used to generate the embeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "                                   model_kwargs={\"device\": \"cuda\"},\n",
    "                                   show_progress=True)\n",
    "\n",
    "# Create a vector database of the code using the supplied embedding function. The returned value will be a\n",
    "# FaissVectorDatabase object.\n",
    "# NOTE: This may take a few minutes to run.\n",
    "faiss_vdb = create_code_embedding(code_dir=os.getenv(\"MORPHEUS_ROOT\"),\n",
    "                                  embedding=embeddings,\n",
    "                                  include_notebooks=False,\n",
    "                                  exclude=[\".cache/**/*.py\", \"build*/**/*.py\"])\n",
    "\n",
    "# Save the vector database to disk\n",
    "code_faiss_dir = os.path.join(os.getenv(\"MORPHEUS_ROOT\"), \".tmp\", \"morpheus_code_faiss\")\n",
    "\n",
    "faiss_vdb.save_local(code_faiss_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0cd628",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> Please wait here until instructed to continue with running the notebook.\n",
    "</div>\n",
    "\n",
    "### 2.3 - Running a RAG Pipeline with Morpheus\n",
    "\n",
    "How do we utilize the Vector Database to answer questions?\n",
    "\n",
    "#### 2.3.1 - Morpheus Overview\n",
    "\n",
    "Quick overview of what Morpheus is and how to use it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ec9cbc52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from morpheus.config import Config\n",
    "from morpheus.config import PipelineModes\n",
    "\n",
    "# Create the pipeline config\n",
    "pipeline_config = Config()\n",
    "pipeline_config.mode = PipelineModes.OTHER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7829100",
   "metadata": {},
   "source": [
    "#### 2.3.2 - Building a Morpheus RAG Pipeline\n",
    "\n",
    "Below, we will build a pipeline that uses Morpheus to answer questions about the code in the repository that we created a vector database for. This works by using the `LLMEngine` in Morpheus with a `RAGNode`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3833deda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "\n",
    "from cyber_dev_day.config import EngineConfig\n",
    "from cyber_dev_day.config import LLMModelConfig\n",
    "from cyber_dev_day.config import NVFoundationLLMModelConfig\n",
    "\n",
    "from morpheus._lib.llm import LLMEngine\n",
    "from morpheus.llm.nodes.extracter_node import ExtracterNode\n",
    "from morpheus.llm.nodes.rag_node import RAGNode\n",
    "from morpheus.llm.services.llm_service import LLMService\n",
    "from morpheus.llm.task_handlers.simple_task_handler import SimpleTaskHandler\n",
    "from morpheus.messages import ControlMessage\n",
    "from morpheus.pipeline.linear_pipeline import LinearPipeline\n",
    "from morpheus.service.vdb.faiss_vdb_service import FaissVectorDBService\n",
    "from morpheus.stages.input.in_memory_source_stage import InMemorySourceStage\n",
    "from morpheus.stages.llm.llm_engine_stage import LLMEngineStage\n",
    "from morpheus.stages.output.in_memory_sink_stage import InMemorySinkStage\n",
    "from morpheus.stages.preprocess.deserialize_stage import DeserializeStage\n",
    "from morpheus.utils.concat_df import concat_dataframes\n",
    "\n",
    "\n",
    "def _build_rag_llm_engine(model_config: LLMModelConfig):\n",
    "\n",
    "    engine = LLMEngine()\n",
    "\n",
    "    engine.add_node(\"extracter\", node=ExtracterNode())\n",
    "\n",
    "    prompt = dedent(\"\"\"\n",
    "    You are a helpful assistant. Given the following background information:\n",
    "    {% for c in contexts -%}\n",
    "    Source File: {{ c.metadata.source }}\n",
    "    Source File Language: {{ c.metadata.language }}\n",
    "    Source Content:\n",
    "    ```\n",
    "    {{ c.page_content }}\n",
    "    ```\n",
    "    {% endfor %}\n",
    "\n",
    "    Please answer the following question:\n",
    "    {{ query }}\n",
    "    \"\"\").strip(\"\\n\")\n",
    "\n",
    "    vector_service = FaissVectorDBService(code_faiss_dir, embeddings=embeddings)\n",
    "\n",
    "    vdb_resource = vector_service.load_resource()\n",
    "\n",
    "    llm_service = LLMService.create(model_config.service.type, **model_config.service.model_dump(exclude={\"type\"}))\n",
    "\n",
    "    llm_client = llm_service.get_client(**model_config.model_dump(exclude={\"service\"}))\n",
    "\n",
    "    # Async wrapper around embeddings\n",
    "    async def calc_embeddings(texts: list[str]) -> list[list[float]]:\n",
    "        return embeddings.embed_documents(texts)\n",
    "\n",
    "    engine.add_node(\"rag\",\n",
    "                    inputs=[\"/extracter\"],\n",
    "                    node=RAGNode(prompt=prompt,\n",
    "                                 vdb_service=vdb_resource,\n",
    "                                 embedding=calc_embeddings,\n",
    "                                 llm_client=llm_client))\n",
    "\n",
    "    engine.add_task_handler(inputs=[\"/rag\"], handler=SimpleTaskHandler())\n",
    "\n",
    "    return engine\n",
    "\n",
    "\n",
    "async def run_rag_pipeline(p_config: Config, model_config: LLMModelConfig, question: str):\n",
    "    source_dfs = [\n",
    "        cudf.DataFrame({\"questions\": [question]}),\n",
    "    ]\n",
    "\n",
    "    completion_task = {\"task_type\": \"completion\", \"task_dict\": {\"input_keys\": [\"questions\"], }}\n",
    "\n",
    "    pipe = LinearPipeline(p_config)\n",
    "\n",
    "    pipe.set_source(InMemorySourceStage(p_config, dataframes=source_dfs))\n",
    "\n",
    "    pipe.add_stage(\n",
    "        DeserializeStage(p_config, message_type=ControlMessage, task_type=\"llm_engine\", task_payload=completion_task))\n",
    "\n",
    "    pipe.add_stage(LLMEngineStage(p_config, engine=_build_rag_llm_engine(model_config)))\n",
    "\n",
    "    sink = pipe.add_stage(InMemorySinkStage(p_config))\n",
    "\n",
    "    await pipe.run_async()\n",
    "\n",
    "    messages = sink.get_messages()\n",
    "    responses = concat_dataframes(messages)\n",
    "\n",
    "    # The responses are quite long, when debug is enabled disable the truncation that pandas and cudf normally\n",
    "    # perform on the output\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    print(\"Response:\\n%s\" % (responses['response'].iloc[0], ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd9f1092",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Pipeline Pre-build====\n",
      "====Pre-Building Segment: linear_segment_0====\n",
      "====Pre-Building Segment Complete!====\n",
      "====Pipeline Pre-build Complete!====\n",
      "====Registering Pipeline====\n",
      "====Building Pipeline====\n",
      "====Building Pipeline Complete!====\n",
      "====Registering Pipeline Complete!====\n",
      "====Starting Pipeline====\n",
      "====Building Segment: linear_segment_0====\n",
      "====Pipeline Started====\n",
      "Added source: <from-mem-0; InMemorySourceStage(dataframes=[                                           questions\n",
      "0  Does the code repo import the `pyarrow_hotfix`...], repeat=1)>\n",
      "  â””â”€> morpheus.MessageMeta\n",
      "Added stage: <deserialize-1; DeserializeStage(ensure_sliceable_index=True, message_type=<class 'morpheus._lib.messages.ControlMessage'>, task_type=llm_engine, task_payload={'task_type': 'completion', 'task_dict': {'input_keys': ['questions']}})>\n",
      "  â””â”€ morpheus.MessageMeta -> morpheus.ControlMessage\n",
      "Added stage: <llm-engine-2; LLMEngineStage(engine=<morpheus._lib.llm.LLMEngine object at 0x7f739850e1b0>)>\n",
      "  â””â”€ morpheus.ControlMessage -> morpheus.ControlMessage\n",
      "Added stage: <to-mem-3; InMemorySinkStage()>\n",
      "  â””â”€ morpheus.ControlMessage -> morpheus.ControlMessage\n",
      "====Building Segment Complete!====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "I20240314 15:30:35.278715   518 asyncio_runnable.hpp:246] AsyncioRunnable::run() > Creating new event loop\n",
      "I20240314 15:30:35.279716   518 asyncio_runnable.hpp:259] AsyncioRunnable::run() > Calling run_until_complete() on main_task()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4125144134334e92a772b380b72ce72b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Pipeline Complete====\n",
      "Response:\n",
      "Yes, the `pyarrow_hotfix` package is imported in the `/workspace/morpheus/__init__.py` file, which is the root package of the Morpheus library. The import statement `import pyarrow_hotfix` can be found near the end of the file.\n"
     ]
    }
   ],
   "source": [
    "model_config = NVFoundationLLMModelConfig.model_validate({\n",
    "    \"service\": {\n",
    "        \"type\": \"nvfoundation\", \"api_key\": None\n",
    "    },\n",
    "    \"model_name\": \"mixtral_8x7b\",\n",
    "    \"temperature\": 0.0\n",
    "})\n",
    "\n",
    "# Run the Pipeline\n",
    "await run_rag_pipeline(pipeline_config, model_config, \"Does the code repo import the `pyarrow_hotfix` package from the `morpheus` root package?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0380153a",
   "metadata": {},
   "source": [
    "#### 2.3.3 - RAG Limitations\n",
    "\n",
    "Using the pipeline we built, we can now ask questions about the code in the repository and the LLM will be able use the vector database to answer them. However, what happens if we need to ask questions about the code that are not in the vector database? For example, what if we needed to ask questions about the dependencies that the code uses? Would the LLM be able to answer these questions? Let's try it out by re-running our RAG pipeline with a more complex question:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "506b5fb3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Pipeline Pre-build====\n",
      "====Pre-Building Segment: linear_segment_0====\n",
      "====Pre-Building Segment Complete!====\n",
      "====Pipeline Pre-build Complete!====\n",
      "====Registering Pipeline====\n",
      "====Building Pipeline====\n",
      "====Building Pipeline Complete!====\n",
      "====Registering Pipeline Complete!====\n",
      "====Starting Pipeline====\n",
      "====Building Segment: linear_segment_0====\n",
      "====Pipeline Started====\n",
      "Added source: <from-mem-4; InMemorySourceStage(dataframes=[                                                            questions\n",
      "0  Does the code repo use `langchain` functions which are deprecated?], repeat=1)>\n",
      "  â””â”€> morpheus.MessageMeta\n",
      "Added stage: <deserialize-5; DeserializeStage(ensure_sliceable_index=True, message_type=<class 'morpheus._lib.messages.ControlMessage'>, task_type=llm_engine, task_payload={'task_type': 'completion', 'task_dict': {'input_keys': ['questions']}})>\n",
      "  â””â”€ morpheus.MessageMeta -> morpheus.ControlMessage\n",
      "Added stage: <llm-engine-6; LLMEngineStage(engine=<morpheus._lib.llm.LLMEngine object at 0x7f739856f9f0>)>\n",
      "  â””â”€ morpheus.ControlMessage -> morpheus.ControlMessage\n",
      "Added stage: <to-mem-7; InMemorySinkStage()>\n",
      "  â””â”€ morpheus.ControlMessage -> morpheus.ControlMessage\n",
      "====Building Segment Complete!====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I20240314 15:30:42.793649   526 asyncio_runnable.hpp:246] AsyncioRunnable::run() > Creating new event loop\n",
      "I20240314 15:30:42.794672   526 asyncio_runnable.hpp:259] AsyncioRunnable::run() > Calling run_until_complete() on main_task()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c05c4da3d106405781fe9863784248f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Pipeline Complete====\n",
      "Response:\n",
      "Based on the provided source files, I cannot determine if the code repo uses `langchain` functions that are deprecated. The `langchain_fixture` function in the `/workspace/tests/examples/llm/common/conftest.py` file only checks if `langchain` is installed and imports it if it is. It does not use any specific functions or methods from the `langchain` package.\n",
      "\n",
      "To determine if `langchain` functions are being used and if they are deprecated, you would need to examine the other source files in the code repo where `langchain` is imported and used. You can check the documentation for the version of `langchain` being used to determine if any of the functions or methods being used are deprecated.\n"
     ]
    }
   ],
   "source": [
    "# Run the Pipeline\n",
    "await run_rag_pipeline(pipeline_config, model_config, \"Does the code repo use `langchain` functions which are deprecated?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abd8482",
   "metadata": {},
   "source": [
    "It's likely that the model was not able to determine the answer to this question because it would need additional information. Depending on the model used, you might see output similar to:\n",
    "\n",
    "```\n",
    "Based on the provided source code, I cannot determine if the `langchain` functions used in the code are deprecated or not.\n",
    "\n",
    "To determine if `langchain` functions are deprecated, you would need to check the documentation for the specific functions being used in the code or consult the maintainers of the `langchain` package.\n",
    "```\n",
    "\n",
    "How would we go about solving this problem?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b81070",
   "metadata": {},
   "source": [
    "### 2.4 - Running the CVE Pipeline with Morpheus\n",
    "\n",
    "#### 2.4.1 - Answering Complex Question with RAG + LLM Agents\n",
    "\n",
    "Intro to LLM Agents and how our checklist + agents approach can help solve multi-step problems.\n",
    "\n",
    "#### 2.4.2 - The Morpheus CVE Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a16bf979",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from cyber_dev_day.pipeline_utils import build_cve_llm_engine\n",
    "\n",
    "from morpheus.messages import ControlMessage\n",
    "from morpheus.pipeline.linear_pipeline import LinearPipeline\n",
    "from morpheus.stages.input.in_memory_source_stage import InMemorySourceStage\n",
    "from morpheus.stages.llm.llm_engine_stage import LLMEngineStage\n",
    "from morpheus.stages.output.in_memory_sink_stage import InMemorySinkStage\n",
    "from morpheus.stages.preprocess.deserialize_stage import DeserializeStage\n",
    "from morpheus.utils.concat_df import concat_dataframes\n",
    "\n",
    "\n",
    "async def run_cve_pipeline(p_config: Config, e_config: EngineConfig, input_cves: list[str]):\n",
    "    source_dfs = [cudf.DataFrame({\"cve_info\": input_cves})]\n",
    "\n",
    "    completion_task = {\"task_type\": \"completion\", \"task_dict\": {\"input_keys\": [\"cve_info\"], }}\n",
    "\n",
    "    pipe = LinearPipeline(p_config)\n",
    "\n",
    "    pipe.set_source(InMemorySourceStage(p_config, dataframes=source_dfs))\n",
    "\n",
    "    pipe.add_stage(\n",
    "        DeserializeStage(p_config, message_type=ControlMessage, task_type=\"llm_engine\", task_payload=completion_task))\n",
    "\n",
    "    pipe.add_stage(LLMEngineStage(p_config, engine=build_cve_llm_engine(e_config)))\n",
    "\n",
    "    sink = pipe.add_stage(InMemorySinkStage(p_config))\n",
    "\n",
    "    await pipe.run_async()\n",
    "\n",
    "    messages = sink.get_messages()\n",
    "    responses = concat_dataframes(messages)\n",
    "\n",
    "    logger.info(\"Pipeline complete\")\n",
    "\n",
    "    logger.info(\"Pipeline complete. Received %s responses:\\n%s\", len(messages), responses['response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf81f7ed",
   "metadata": {},
   "source": [
    "#### 2.4.2 - The Engine Config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b628e418",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from cyber_dev_day.config import EngineConfig\n",
    "\n",
    "# Create the engine configuration\n",
    "engine_config = EngineConfig.model_validate({\n",
    "    'checklist': {\n",
    "        'model': {\n",
    "            'service': {\n",
    "                'type': 'nemo', 'api_key': None, 'org_id': None\n",
    "            },\n",
    "            'model_name': 'gpt-43b-002',\n",
    "            'customization_id': None,\n",
    "            'temperature': 0.0,\n",
    "            'tokens_to_generate': 300\n",
    "        }\n",
    "    },\n",
    "    'agent': {\n",
    "        'model': {\n",
    "            'service': {\n",
    "                'type': 'nvfoundation', 'api_key': None\n",
    "            }, 'model_name': 'mixtral_8x7b', 'temperature': 0.0\n",
    "        },\n",
    "        'sbom': {\n",
    "            'data_file':\n",
    "                os.path.join(os.getenv(\"MORPHEUS_ROOT\", \"../..\"),\n",
    "                             \"examples\",\n",
    "                             \"cyber_dev_day\",\n",
    "                             \"data\",\n",
    "                             \"morpheus_24.03-runtime_sbom.csv\")\n",
    "        },\n",
    "        'code_repo': {\n",
    "            'faiss_dir': code_faiss_dir, 'embedding_model_name': \"sentence-transformers/all-mpnet-base-v2\"\n",
    "        }\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09f759e4-fc8c-4c84-ba15-3f3408a2bff3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"checklist\": {\n",
      "    \"model\": {\n",
      "      \"service\": {\n",
      "        \"type\": \"nemo\",\n",
      "        \"api_key\": null,\n",
      "        \"org_id\": null\n",
      "      },\n",
      "      \"model_name\": \"gpt-43b-002\",\n",
      "      \"customization_id\": null,\n",
      "      \"temperature\": 0.0,\n",
      "      \"tokens_to_generate\": 300\n",
      "    }\n",
      "  },\n",
      "  \"agent\": {\n",
      "    \"model\": {\n",
      "      \"service\": {\n",
      "        \"type\": \"nvfoundation\",\n",
      "        \"api_key\": null\n",
      "      },\n",
      "      \"model_name\": \"mixtral_8x7b\",\n",
      "      \"temperature\": 0.0\n",
      "    },\n",
      "    \"sbom\": {\n",
      "      \"data_file\": \"/workspace/examples/cyber_dev_day/data/morpheus_24.03-runtime_sbom.csv\"\n",
      "    },\n",
      "    \"code_repo\": {\n",
      "      \"faiss_dir\": \"/workspace/.tmp/morpheus_code_faiss\",\n",
      "      \"embedding_model_name\": \"sentence-transformers/all-mpnet-base-v2\"\n",
      "    },\n",
      "    \"verbose\": true\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Print the current configuration object\n",
    "print(engine_config.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806649e4",
   "metadata": {},
   "source": [
    "#### 2.4.3 - Running the Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "001ee70c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Pipeline Pre-build====\n",
      "====Pre-Building Segment: linear_segment_0====\n",
      "====Pre-Building Segment Complete!====\n",
      "====Pipeline Pre-build Complete!====\n",
      "====Registering Pipeline====\n",
      "====Building Pipeline====\n",
      "====Building Pipeline Complete!====\n",
      "====Registering Pipeline Complete!====\n",
      "====Starting Pipeline====\n",
      "====Building Segment: linear_segment_0====\n",
      "====Pipeline Started====\n",
      "Added source: <from-mem-8; InMemorySourceStage(dataframes=[                                                                                                                                                                       cve_info\n",
      "0  An issue was discovered in the Linux kernel through 6.0.9. drivers/media/dvb-core/dvbdev.c has a use-after-free, related to dvb_register_device dynamically allocating fops.], repeat=1)>\n",
      "  â””â”€> morpheus.MessageMeta\n",
      "Added stage: <deserialize-9; DeserializeStage(ensure_sliceable_index=True, message_type=<class 'morpheus._lib.messages.ControlMessage'>, task_type=llm_engine, task_payload={'task_type': 'completion', 'task_dict': {'input_keys': ['cve_info']}})>\n",
      "  â””â”€ morpheus.MessageMeta -> morpheus.ControlMessage\n",
      "Added stage: <llm-engine-10; LLMEngineStage(engine=<morpheus._lib.llm.LLMEngine object at 0x7f73680b9930>)>\n",
      "  â””â”€ morpheus.ControlMessage -> morpheus.ControlMessage\n",
      "Added stage: <to-mem-11; InMemorySinkStage()>\n",
      "  â””â”€ morpheus.ControlMessage -> morpheus.ControlMessage\n",
      "====Building Segment Complete!====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/morpheus/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n",
      "I20240314 15:31:11.797904   542 asyncio_runnable.hpp:246] AsyncioRunnable::run() > Creating new event loop\n",
      "I20240314 15:31:11.811787   542 asyncio_runnable.hpp:259] AsyncioRunnable::run() > Calling run_until_complete() on main_task()\n",
      "/opt/conda/envs/morpheus/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `arun` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use ainvoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to check if the Docker container's Linux kernel has the mentioned use-after-free vulnerability in the specified file and function. To do this, I can first use the SBOM Package Checker to see if the Linux kernel is present in the container and get its version number. Then, I can use the Docker Container Code QA System to check if the container's Linux kernel uses the problematic function in the given file.\n",
      "\n",
      "Action: SBOM Package Checker\n",
      "Action Input: Linux kernel\n",
      "\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe package Linux kernel\n",
      "\n",
      " was not found in the SBOM\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mIt seems that the SBOM Package Checker did not find the Linux kernel in the Docker container. This might be because the container is using a custom-built kernel or the SBOM is not complete. In any case, without knowing the kernel version, it's impossible to determine if the use-after-free vulnerability is present. I would recommend further investigation into why the Linux kernel is not present in the SBOM or checking if there's an alternative way to determine the kernel version.\n",
      "\n",
      "Final Answer: I cannot determine if the Docker container's Linux kernel has the mentioned use-after-free vulnerability in the specified file and function due to the Linux kernel not being present in the SBOM.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "====Pipeline Complete====\n",
      "Pipeline complete\n",
      "Pipeline complete. Received 1 responses:\n",
      "\"\"\n",
      "0    I cannot determine if the Docker container's Linux kernel has the mentioned use-after-free vulnerability in the specified file and function due to the Linux kernel not being present in the SBOM.\n",
      "Name: response, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Now run the pipeline with a specified CVE description\n",
    "await run_cve_pipeline(pipeline_config, engine_config, [\n",
    "    \"An issue was discovered in the Linux kernel through 6.0.9. drivers/media/dvb-core/dvbdev.c has a use-after-free, related to dvb_register_device dynamically allocating fops.\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4b8a57",
   "metadata": {},
   "source": [
    "#### 2.4.4 - Hitting the Limits of the LLMs\n",
    "\n",
    "This section will go over some of the areas where LLMs may fail.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7e791c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example to cause the LLM to fail (TBD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8c30da",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> Please wait here until instructed to continue with running the notebook.\n",
    "</div>\n",
    "\n",
    "## 3 - Beyond Prototyping\n",
    "\n",
    "Up until now, we have been using the pipeline we built to answer questions about the code in the repository. While this works for a few hand picked use cases, it is not suitable to deploy into a production environment for several reasons:\n",
    "\n",
    "1. The LLM models fail to work on some questions which can generate errors in the pipeline\n",
    "   1. Since the pipeline chains many LLM calls together, a single error can cause the entire pipeline to fail. For a production environment, we would need to handle these errors more gracefully or improve the model to reduce the number of errors.\n",
    "2. The pipeline is not optimized for performance\n",
    "   1. The pipeline is slow to run, because each model needs to be executed sequentially. For a production environment, we would need to optimize the pipeline handle multiple requests at once.\n",
    "3. The pipeline cannot be easily integrated into other systems\n",
    "   1. The pipeline is a standalone script which reads from a single file and needs to be run manually. For a production environment, the pipeline would need to be integrated with other systems, such as a web server or a chatbot.\n",
    "\n",
    "In this section, we will address each of the limitations we encountered in the previous section and discuss how we can overcome them utilizing NeMo and Morpheus.\n",
    "\n",
    "### 3.1 - Improving the Model\n",
    "\n",
    "Although few-shot learning can be effective for many use cases, there are situations where enhancing certain aspects of the model's output or providing a broader range of examples is desirable.\n",
    "\n",
    "While augmenting the prompt with more examples can further refine the model, there comes a point where the extended prompt becomes cumbersome, leading to longer processing times and higher costs due to increased token usage in each query.\n",
    "\n",
    "A practical alternative is to compile your examples into a dataset and fine-tune the base model to achieve improved performance on a targeted task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dcc38b-8ebb-4cf6-aa30-380fd16ee178",
   "metadata": {},
   "source": [
    "#### 3.1.1 - Log4j Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f74deaea-e398-4b8c-b13a-24b0f270de4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LOG4J_CVE_INTEL = dict(\n",
    "    cve=\"CVE-2021-44228\",\n",
    "    cve_description=\n",
    "    \"Apache Log4j2 2.0-beta9 through 2.15.0 (excluding security releases 2.12.2, 2.12.3, and 2.3.1) JNDI features used in \"\n",
    "    \"configuration, log messages, and parameters do not protect against attacker controlled LDAP and other JNDI related endpoints. An attacker \"\n",
    "    \"who can control log messages or log message parameters can execute arbitrary code loaded from LDAP servers when message lookup substitution \"\n",
    "    \"is enabled. From log4j 2.15.0, this behavior has been disabled by default. From version 2.16.0 (along with 2.12.2, 2.12.3, and 2.3.1), this \"\n",
    "    \"functionality has been completely removed. Note that this vulnerability is specific to log4j-core and does not affect log4net, log4cxx, or \"\n",
    "    \"other Apache Logging Services projects.\",\n",
    "    vuln_package=\"log4j\",\n",
    "    vuln_package_version=\n",
    "    \"from 2.0.1 up to (excluding) 2.3.1, from 2.4.0 up to (excluding) 2.12.2, from 2.13.0 up to (excluding) 2.15.0\",\n",
    "    cvss3=\"CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:C/C:H/I:H/A:H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14ecf15b-e1e4-43db-9aca-6578211469aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\n",
      "    \"Check for log4j: Verify if your project uses the log4j library, which is the affected package. If log4j is not a dependency in your project, then your code is not vulnerable to this CVE.\",\n",
      "    \"Review Affected Versions: If log4j is used, check the version that your project depends on. According to the vulnerability details, versions from 2.0.1 up to (excluding) 2.3.1, from 2.4.0 up to (excluding) 2.12.2, from 2.13.0 up to (excluding) 2.15.0 are affected by this vulnerability.\",\n",
      "    \"Review Code To Check for Vulnerability Mitigation: Check if the 'log4j-core' library is not used in your project. If it is used, check if the 'log4j-core' library is updated to the latest version (2.16.0) or a version that includes the security release (2.12.2, 2.12.3, or 2.3.1).\",\n",
      "    \"Check for use of vulnerable functions: The library is vulnerable through its JNDI features. Check if any of these features are used in your code base.\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "formatted_prompt = few_shot_prompt_template.format(**LOG4J_CVE_INTEL)\n",
    "\n",
    "model_output = conn.generate(\n",
    "    prompt=formatted_prompt,\n",
    "    model=\"gpt-43b-002\",\n",
    "    tokens_to_generate=512,\n",
    "    temperature=0,\n",
    "    return_type=\"text\",\n",
    "    stop=[\"]\"],\n",
    ")\n",
    "\n",
    "print(model_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554962c5-0efd-445f-b321-2853f027cf9c",
   "metadata": {},
   "source": [
    "In the example above, the model utilizing a **few-shot learning** prompt effectively **identifies the basic checks**, similar to what's shown in the in-context examples. However, it **doesn't include checks related to the vulnerable configurations** (message lookup substitution) and the **usage of vulnerable feature** (JNDI).\n",
    "\n",
    "Instead of incorporating this Log4j CVE as an **additional example** in the prompt, a more effective strategy would be to create a **fine-tuning dataset** that includes this scenario. This dataset can then be used to fine-tune the model, aligning its performance more closely with our expectations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a61a762-3219-4b2b-aedf-836ce1a7f2f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 3.1.2 - Fine-Tuning Dataset\n",
    "\n",
    "The fine-tuning dataset would need you to build out your ideal output to train the model towards:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ebad28c-b991-4705-809c-d908e7f134f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Target checklists\n",
    "PYARROW_CHECKLIST = \"\"\"[\n",
    "    \"Check for PyArrow: Verify if your project uses the PyArrow library, which is the affected package. If PyArrow is not a dependency in your project, then your code is not vulnerable to this CVE.\",\n",
    "    \"Review Affected Versions: If PyArrow is used, check the version of PyArrow that your project depends on. According to the vulnerability details, versions from 0.14.0 to 14.0.0 are affected by this vulnerability.\",\n",
    "    \"Check for pyarrow-hotfix: Verify if your project already contains the pyarrow-hotfix package made to remediate this CVE.\"\n",
    "]\"\"\"\n",
    "LOG4J_CHECKLIST = \"\"\"[\n",
    "    \"Check for log4j: Verify if your project uses the log4j library, which is the affected package. If log4j is not a dependency in your project, then your code is not vulnerable to this CVE.\",\n",
    "    \"Check for log4j-core: Specifically check for usage of log4j-core library, as this vulnerability is specific to log4j-core and does not affect other Apache Logging Services projects such as log4net or log4cxx.\",\n",
    "    \"Review Affected Versions: If log4j-core is used, check the log4j version that your project depends on. According to the vulnerability details, versions from 2.0.1 up to (excluding) 2.3.1, from 2.4.0 up to (excluding) 2.12.2, and from 2.13.0 up to (excluding) 2.15.0 are affected by this vulnerability.\",\n",
    "    \"Review Code for Usage of Vulnerable Features: Check if JNDI features are used in configuration, log messages, or parameters within your code base. If so, ensure that attacker-controlled inputs are not used to load arbitrary code from LDAP servers.\",\n",
    "    \"Check for Vulnerable Configuration: If JNDI features are used, ensure that message lookup substitution is not enabled, as enabling it could allow an attacker to execute arbitrary code loaded from LDAP servers through controlled log messages or log message parameters.\"\n",
    "]\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c997d7c-b10c-460d-854d-b236a033692d",
   "metadata": {},
   "source": [
    "Datasets required for fine-tuning have examples with just two fields- `Prompt` and `Completion`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e2c3ba22-2638-4fda-b26b-0be27fe02570",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_examples = [(PYARROW_CVE_INTEL, PYARROW_CHECKLIST), (LOG4J_CVE_INTEL, LOG4J_CHECKLIST)]  # and potentially many more\n",
    "data = []\n",
    "for cve_intel, target_checklist in my_examples:\n",
    "    formatted_prompt = few_shot_prompt_template.format(**LOG4J_CVE_INTEL)\n",
    "    completion = target_checklist\n",
    "    data.append({\n",
    "        \"prompt\": formatted_prompt,\n",
    "        \"completion\": completion,\n",
    "    })\n",
    "\n",
    "# # Next step would be to save this dataset out into a jsonl file\n",
    "# file_path = './my_fine_tune_dataset.jsonl'\n",
    "\n",
    "# with open(file_path, 'w') as file:\n",
    "#     for record in data:\n",
    "#         json_record = json.dumps(record)\n",
    "#         file.write(f\"{json_record}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c05400-f63d-419f-8b4a-af8e11c5d055",
   "metadata": {},
   "source": [
    "Now we can fine-tune the model with this dataset using Nemo and swap it into our pipeline by just adding a `customization_id`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdbbf47-2542-4c59-bc6a-b63fbd8d307b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 3.1.3 - Fine-tuned Model\n",
    "\n",
    "The following cell deomstrates the call to a fine-tuned model and its output for the Log4j CVE:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f9955693-e9dd-4352-b981-7dce927d1af7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\n",
      "    \"Check for log4j: Verify if your project uses the log4j library, which is the affected package. If log4j is not a dependency in your project, then your code is not vulnerable to this CVE.\",\n",
      "    \"Review Affected Versions: If log4j is used, check the version that your project depends on. According to the vulnerability details, versions from 2.0.1 up to (excluding) 2.3.1, from 2.4.0 up to (excluding) 2.12.2, from 2.13.0 up to (excluding) 2.15.0 are affected by this vulnerability.\",\n",
      "    \"Review Code to Check for Vulnerability Mitigation: Check if the 'log4j-core' library is not used in your project. If it is used, check if the 'log4j-core' library is updated to the latest version (2.16.0) or a version that includes the security release (2.12.2, 2.12.3, or 2.3.1).\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "formatted_prompt = few_shot_prompt_template.format(**LOG4J_CVE_INTEL)\n",
    "\n",
    "model_output = conn.generate(\n",
    "    prompt=formatted_prompt,\n",
    "    model=\"gpt-43b-002-lora\",\n",
    "    # customization_id=\"96d79918-f5a8-47c0-8b0e-b87295e51b64\",  # PLACEHOLDER\n",
    "    tokens_to_generate=800,\n",
    "    temperature=0.001,\n",
    "    return_type=\"text\",\n",
    ")\n",
    "\n",
    "print(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f91ef4fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Pipeline Pre-build====\n",
      "====Pre-Building Segment: linear_segment_0====\n",
      "====Pre-Building Segment Complete!====\n",
      "====Pipeline Pre-build Complete!====\n",
      "====Registering Pipeline====\n",
      "====Building Pipeline====\n",
      "====Building Pipeline Complete!====\n",
      "====Registering Pipeline Complete!====\n",
      "====Starting Pipeline====\n",
      "====Building Segment: linear_segment_0====\n",
      "====Pipeline Started====\n",
      "Added source: <from-mem-12; InMemorySourceStage(dataframes=[                                                                                                                                                                       cve_info\n",
      "0  An issue was discovered in the Linux kernel through 6.0.9. drivers/media/dvb-core/dvbdev.c has a use-after-free, related to dvb_register_device dynamically allocating fops.], repeat=1)>\n",
      "  â””â”€> morpheus.MessageMeta\n",
      "Added stage: <deserialize-13; DeserializeStage(ensure_sliceable_index=True, message_type=<class 'morpheus._lib.messages.ControlMessage'>, task_type=llm_engine, task_payload={'task_type': 'completion', 'task_dict': {'input_keys': ['cve_info']}})>\n",
      "  â””â”€ morpheus.MessageMeta -> morpheus.ControlMessage\n",
      "Added stage: <llm-engine-14; LLMEngineStage(engine=<morpheus._lib.llm.LLMEngine object at 0x7f71fc36c3f0>)>\n",
      "  â””â”€ morpheus.ControlMessage -> morpheus.ControlMessage\n",
      "Added stage: <to-mem-15; InMemorySinkStage()>\n",
      "  â””â”€ morpheus.ControlMessage -> morpheus.ControlMessage\n",
      "====Building Segment Complete!====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I20240314 15:31:45.066318   561 asyncio_runnable.hpp:246] AsyncioRunnable::run() > Creating new event loop\n",
      "I20240314 15:31:45.077411   561 asyncio_runnable.hpp:259] AsyncioRunnable::run() > Calling run_until_complete() on main_task()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to check if the Docker container's Linux kernel has the mentioned use-after-free vulnerability in the specified file and function. To do this, I can first use the SBOM Package Checker to see if the Linux kernel is present in the container and get its version number. Then, I can use the Docker Container Code QA System to check if the container's Linux kernel uses the problematic function in the given file.\n",
      "\n",
      "Action: SBOM Package Checker\n",
      "Action Input: Linux kernel\n",
      "\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe package Linux kernel\n",
      "\n",
      " was not found in the SBOM\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mIt seems that the SBOM Package Checker did not find the Linux kernel in the Docker container. This might be because the container is using a custom-built kernel or the SBOM is not complete. In any case, without knowing the kernel version, it's impossible to determine if the use-after-free vulnerability is present. I would recommend further investigation into why the Linux kernel is not present in the SBOM or checking if there's an alternative way to determine the kernel version.\n",
      "\n",
      "Final Answer: I cannot determine if the Docker container's Linux kernel has the mentioned use-after-free vulnerability in the specified file and function due to the Linux kernel not being present in the SBOM.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "====Pipeline Complete====\n",
      "Pipeline complete\n",
      "Pipeline complete. Received 1 responses:\n",
      "\"\"\n",
      "0    I cannot determine if the Docker container's Linux kernel has the mentioned use-after-free vulnerability in the specified file and function due to the Linux kernel not being present in the SBOM.\n",
      "Name: response, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Code for improving the model\n",
    "engine_config_custom_model = engine_config.model_copy(deep=True)\n",
    "\n",
    "# Set the customization ID\n",
    "# engine_config_custom_model.checklist.model.customization_id = \"<CUSTOMIZATION_ID>\"\n",
    "\n",
    "# Run the pipeline\n",
    "await run_cve_pipeline(pipeline_config, engine_config_custom_model, [\n",
    "    \"An issue was discovered in the Linux kernel through 6.0.9. drivers/media/dvb-core/dvbdev.c has a use-after-free, related to dvb_register_device dynamically allocating fops.\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a826b5",
   "metadata": {},
   "source": [
    "### 3.2 - Scaling the Pipeline\n",
    "\n",
    "When running pipelines which utilize LLMs, it's important to understand how the LLMs are executed to parallelize their execution as much as possible. This is because LLMs can take a long time to run, as low as a few hundred milliseconds and upwards of a few seconds. Running LLMs serially can compound those runtimes leading to execution times that grow linearly with the number of LLM requests. A simple diagram of the execution of LLMs for our CVE pipeline is shown below:\n",
    "\n",
    "![Single CVE - Serial](./images/single_cve_serial.jpg)\n",
    "\n",
    "In the diagram above, we can see that the LLMs are executed serially, one after the other. This is not ideal as the execution time of the pipeline is directly proportional to the number of LLMs that are executed. However, there is no dependency between the LLM calls in each of checklist items. This means that we can parallelize the execution of the LLMs to reduce the overall execution time of the pipeline. A simple diagram of the parallel execution of LLMs for our CVE pipeline is shown below:\n",
    "\n",
    "![Single CVE - Parallel](./images/single_cve_parallel.jpg)\n",
    "\n",
    "In the diagram above, we can see that the total execution time has been reduced as the checklist agent LLMs are executed in parallel. The total execution time is now the maximum time taken to execute any of the LLM agent chains. This is a significant improvement over the serial execution of the LLMs. But what happens if we need to run the entire pipeline for multiple CVEs? A naive approach would be to run the pipeline for each CVE serially, which is shown below:\n",
    "\n",
    "![Multiple CVE - Serial](./images/multiple_cve_serial.jpg)\n",
    "\n",
    "With most LLM libraries, this is the default behavior and improving on this requires more complex solutions such as multiprocessing or distributed workers. However, with Morpheus, this is trivial since Morpheus benefits from pipeline parallelism where each message is processed in an assembly line fashion. This means that we can start processing the next message before the previous one is even completed. A simple diagram of the parallel execution of the pipeline for multiple CVEs is shown below:\n",
    "\n",
    "![Multiple CVE - Parallel](./images/multiple_cve_parallel.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "895f9bcf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Pipeline Pre-build====\n",
      "====Pre-Building Segment: linear_segment_0====\n",
      "====Pre-Building Segment Complete!====\n",
      "====Pipeline Pre-build Complete!====\n",
      "====Registering Pipeline====\n",
      "====Building Pipeline====\n",
      "====Building Pipeline Complete!====\n",
      "====Registering Pipeline Complete!====\n",
      "====Starting Pipeline====\n",
      "====Pipeline Started====\n",
      "====Building Segment: linear_segment_0====\n",
      "Added source: <from-mem-16; InMemorySourceStage(dataframes=[                                                                                                                                                                       cve_info\n",
      "0  An issue was discovered in the Linux kernel through 6.0.9. drivers/media/dvb-core/dvbdev.c has a use-after-free, related to dvb_register_device dynamically allocating fops.\n",
      "1  An issue was discovered in the Linux kernel through 6.0.9. drivers/media/dvb-core/dvbdev.c has a use-after-free, related to dvb_register_device dynamically allocating fops.\n",
      "2  An issue was discovered in the Linux kernel through 6.0.9. drivers/media/dvb-core/dvbdev.c has a use-after-free, related to dvb_register_device dynamically allocating fops.\n",
      "3  An issue was discovered in the Linux kernel through 6.0.9. drivers/media/dvb-core/dvbdev.c has a use-after-free, related to dvb_register_device dynamically allocating fops.\n",
      "4  An issue was discovered in the Linux kernel through 6.0.9. drivers/media/dvb-core/dvbdev.c has a use-after-free, related to dvb_register_device dynamically allocating fops.], repeat=1)>\n",
      "  â””â”€> morpheus.MessageMeta\n",
      "Added stage: <deserialize-17; DeserializeStage(ensure_sliceable_index=True, message_type=<class 'morpheus._lib.messages.ControlMessage'>, task_type=llm_engine, task_payload={'task_type': 'completion', 'task_dict': {'input_keys': ['cve_info']}})>\n",
      "  â””â”€ morpheus.MessageMeta -> morpheus.ControlMessage\n",
      "Added stage: <llm-engine-18; LLMEngineStage(engine=<morpheus._lib.llm.LLMEngine object at 0x7f71fc37b570>)>\n",
      "  â””â”€ morpheus.ControlMessage -> morpheus.ControlMessage\n",
      "Added stage: <to-mem-19; InMemorySinkStage()>\n",
      "  â””â”€ morpheus.ControlMessage -> morpheus.ControlMessage\n",
      "====Building Segment Complete!====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I20240314 15:32:17.959069   574 asyncio_runnable.hpp:246] AsyncioRunnable::run() > Creating new event loop\n",
      "I20240314 15:32:17.960040   574 asyncio_runnable.hpp:259] AsyncioRunnable::run() > Calling run_until_complete() on main_task()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to check if the Docker container's Linux kernel has the mentioned use-after-free vulnerability in the specified file and function. To do this, I can first use the SBOM Package Checker to see if the Linux kernel is present in the container and get its version number. Then, I can use the Docker Container Code QA System to check if the container's Linux kernel uses the problematic function in the given file.\n",
      "\n",
      "Action: SBOM Package Checker\n",
      "Action Input: Linux kernel\n",
      "\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3mI need to check if the Docker container's Linux kernel has the mentioned use-after-free vulnerability in the specified file and function. To do this, I can first use the SBOM Package Checker to see if the Linux kernel is present in the container and get its version number. Then, I can use the Docker Container Code QA System to check if the container's Linux kernel uses the problematic function in the given file.\n",
      "\n",
      "Action: SBOM Package Checker\n",
      "Action Input: Linux kernel\n",
      "\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3mI need to check if the Docker container's Linux kernel has the mentioned use-after-free vulnerability in the specified file and function. To do this, I can first use the SBOM Package Checker to see if the Linux kernel is present in the container and get its version number. Then, I can use the Docker Container Code QA System to check if the container's Linux kernel uses the problematic function in the given file.\n",
      "\n",
      "Action: SBOM Package Checker\n",
      "Action Input: Linux kernel\n",
      "\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe package Linux kernel\n",
      "\n",
      " was not found in the SBOM\u001b[0m\n",
      "Thought:\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe package Linux kernel\n",
      "\n",
      " was not found in the SBOM\u001b[0m\n",
      "Thought:\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe package Linux kernel\n",
      "\n",
      " was not found in the SBOM\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to check if the Docker container's Linux kernel has the mentioned use-after-free vulnerability in the specified file and function. To do this, I can first use the SBOM Package Checker to see if the Linux kernel is present in the container and get its version number. Then, I can use the Docker Container Code QA System to check if the container's Linux kernel uses the problematic function in the given file.\n",
      "\n",
      "Action: SBOM Package Checker\n",
      "Action Input: Linux kernel\n",
      "\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3mI need to check if the Docker container's Linux kernel has the mentioned use-after-free vulnerability in the specified file and function. To do this, I can first use the SBOM Package Checker to see if the Linux kernel is present in the container and get its version number. Then, I can use the Docker Container Code QA System to check if the container's Linux kernel uses the problematic function in the given file.\n",
      "\n",
      "Action: SBOM Package Checker\n",
      "Action Input: Linux kernel\n",
      "\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe package Linux kernel\n",
      "\n",
      " was not found in the SBOM\u001b[0m\n",
      "Thought:\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe package Linux kernel\n",
      "\n",
      " was not found in the SBOM\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mIt seems that the SBOM Package Checker did not find the Linux kernel in the Docker container. This might be because the container is using a custom-built kernel or the SBOM is not complete. In any case, without knowing the kernel version, it's impossible to determine if the use-after-free vulnerability is present. I would recommend further investigation into why the Linux kernel is not present in the SBOM or checking if there's an alternative way to determine the kernel version.\n",
      "\n",
      "Final Answer: I cannot determine if the Docker container's Linux kernel has the mentioned use-after-free vulnerability in the specified file and function due to the Linux kernel not being present in the SBOM.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mIt seems that the SBOM Package Checker did not find the Linux kernel in the Docker container. This might be because the container is using a custom-built kernel or the SBOM is not complete. In any case, without knowing the kernel version, it's impossible to determine if the use-after-free vulnerability is present. I would recommend further investigation into why the Linux kernel is not present in the SBOM or checking if there's an alternative way to determine the kernel version.\n",
      "\n",
      "Final Answer: I cannot determine if the Docker container's Linux kernel has the mentioned use-after-free vulnerability in the specified file and function due to the Linux kernel not being present in the SBOM.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mIt seems that the SBOM Package Checker did not find the Linux kernel in the Docker container. This might be because the container is using a custom-built kernel or the SBOM is not complete. In any case, without knowing the kernel version, it's impossible to determine if the use-after-free vulnerability is present. I would recommend further investigation into why the Linux kernel is not present in the SBOM or checking if there's an alternative way to determine the kernel version.\n",
      "\n",
      "Final Answer: I cannot determine if the Docker container's Linux kernel has the mentioned use-after-free vulnerability in the specified file and function due to the Linux kernel not being present in the SBOM.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mIt seems that the SBOM Package Checker did not find the Linux kernel in the Docker container. This might be because the container is using a custom-built kernel or the SBOM is not complete. In any case, without knowing the kernel version, it's impossible to determine if the use-after-free vulnerability is present. I would recommend further investigation into why the Linux kernel is not present in the SBOM or checking if there's an alternative way to determine the kernel version.\n",
      "\n",
      "Final Answer: I cannot determine if the Docker container's Linux kernel has the mentioned use-after-free vulnerability in the specified file and function due to the Linux kernel not being present in the SBOM.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mIt seems that the SBOM Package Checker did not find the Linux kernel in the Docker container. This might be because the container is using a custom-built kernel or the SBOM is not complete. In any case, without knowing the kernel version, it's impossible to determine if the use-after-free vulnerability is present. I would recommend further investigation into why the Linux kernel is not present in the SBOM or checking if there's an alternative way to determine the kernel version.\n",
      "\n",
      "Final Answer: I cannot determine if the Docker container's Linux kernel has the mentioned use-after-free vulnerability in the specified file and function due to the Linux kernel not being present in the SBOM.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "====Pipeline Complete====\n",
      "Pipeline complete\n",
      "Pipeline complete. Received 1 responses:\n",
      "\"\"\n",
      "0    I cannot determine if the Docker container's Linux kernel has the mentioned use-after-free vulnerability in the specified file and function due to the Linux kernel not being present in the SBOM.\n",
      "1    I cannot determine if the Docker container's Linux kernel has the mentioned use-after-free vulnerability in the specified file and function due to the Linux kernel not being present in the SBOM.\n",
      "2    I cannot determine if the Docker container's Linux kernel has the mentioned use-after-free vulnerability in the specified file and function due to the Linux kernel not being present in the SBOM.\n",
      "3    I cannot determine if the Docker container's Linux kernel has the mentioned use-after-free vulnerability in the specified file and function due to the Linux kernel not being present in the SBOM.\n",
      "4    I cannot determine if the Docker container's Linux kernel has the mentioned use-after-free vulnerability in the specified file and function due to the Linux kernel not being present in the SBOM.\n",
      "Name: response, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Create multiple CVE requests\n",
    "cves = [\n",
    "    (\"An issue was discovered in the Linux kernel through 6.0.9. drivers/media/dvb-core/dvbdev.c has a use-after-free, \"\n",
    "     \"related to dvb_register_device dynamically allocating fops.\"),\n",
    "     (\"An issue was discovered in the Linux kernel through 6.0.9. drivers/media/dvb-core/dvbdev.c has a use-after-free, \"\n",
    "     \"related to dvb_register_device dynamically allocating fops.\"),\n",
    "     (\"An issue was discovered in the Linux kernel through 6.0.9. drivers/media/dvb-core/dvbdev.c has a use-after-free, \"\n",
    "     \"related to dvb_register_device dynamically allocating fops.\"),\n",
    "     (\"An issue was discovered in the Linux kernel through 6.0.9. drivers/media/dvb-core/dvbdev.c has a use-after-free, \"\n",
    "     \"related to dvb_register_device dynamically allocating fops.\"),\n",
    "     (\"An issue was discovered in the Linux kernel through 6.0.9. drivers/media/dvb-core/dvbdev.c has a use-after-free, \"\n",
    "     \"related to dvb_register_device dynamically allocating fops.\")\n",
    "]\n",
    "\n",
    "await run_cve_pipeline(pipeline_config, engine_config_custom_model, cves)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c266d439",
   "metadata": {},
   "source": [
    "If you look at the above output, you should see a section that looks like the following:\n",
    "\n",
    "```\n",
    "> Entering new AgentExecutor chain...\n",
    "\n",
    "> Entering new AgentExecutor chain...\n",
    "\n",
    "> Entering new AgentExecutor chain...\n",
    "\n",
    "> Entering new AgentExecutor chain...\n",
    "\n",
    "> Entering new AgentExecutor chain...\n",
    "```\n",
    "\n",
    "Because each executor chain is being started before the previous one completes, they are all running in parallel. But can we verify that this is actually leading to a performance improvement? Let's run the pipeline for a single CVE and multiple CVEs and compare their execution time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1f51590",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I20240314 15:32:31.123289   590 asyncio_runnable.hpp:246] AsyncioRunnable::run() > Creating new event loop\n",
      "I20240314 15:32:31.133785   590 asyncio_runnable.hpp:259] AsyncioRunnable::run() > Calling run_until_complete() on main_task()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing 1 CVE(s). Total: 3378.716468811035 ms, Average: 3378.716468811035 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I20240314 15:32:34.345867   598 asyncio_runnable.hpp:246] AsyncioRunnable::run() > Creating new event loop\n",
      "I20240314 15:32:34.346040   598 asyncio_runnable.hpp:259] AsyncioRunnable::run() > Calling run_until_complete() on main_task()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing 5 CVE(s). Total: 3542.999744415283 ms, Average: 708.5999488830566 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I20240314 15:32:37.541440   612 asyncio_runnable.hpp:246] AsyncioRunnable::run() > Creating new event loop\n",
      "I20240314 15:32:37.543920   612 asyncio_runnable.hpp:259] AsyncioRunnable::run() > Calling run_until_complete() on main_task()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing 10 CVE(s). Total: 3314.418315887451 ms, Average: 331.4418315887451 ms\n"
     ]
    }
   ],
   "source": [
    "from morpheus.utils.logging_timer import log_time\n",
    "\n",
    "# Update the agent config to disable verbose logging\n",
    "non_verbose_config = engine_config_custom_model.model_copy(deep=True)\n",
    "non_verbose_config.agent.verbose = False\n",
    "\n",
    "# Disable the logger to make it easer to see the timings\n",
    "saved_level = logger.parent.level\n",
    "logger.parent.setLevel(logging.ERROR)\n",
    "\n",
    "execution_times: dict[int, float] = {}\n",
    "\n",
    "for count in [1, 5, 10]:\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    with log_time(print, count=count, msg=\"Executing {count} CVE(s). Total: {duration} ms, Average: {ms_per_count} ms\"):\n",
    "        await run_cve_pipeline(pipeline_config, non_verbose_config, [cves[0]] * count)\n",
    "\n",
    "    execution_times[count] = time.time() - start_time\n",
    "\n",
    "logger.parent.setLevel(saved_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138ebec5",
   "metadata": {},
   "source": [
    "Your actual execution time may differ, but it should look something like the following:\n",
    "\n",
    "```\n",
    "Executing 1 CVE(s). Total: 6047.4913120269775 ms, Average: 6047.4913120269775 ms\n",
    "Executing 5 CVE(s). Total: 5316.500663757324 ms, Average: 1063.3001327514648 ms\n",
    "Executing 10 CVE(s). Total: 5708.996534347534 ms, Average: 570.8996534347534 ms\n",
    "```\n",
    "\n",
    "As you can see, the total execution time for the pipeline for multiple CVEs is close to the total execution time for the pipeline for a single CVE. To get an idea of how well the pipeline scales, we can make a plot of the CVE count vs runtimes for the pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e84b6723",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# importing matplotlib module\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Function to plot\n",
    "plt.plot(execution_times.keys(),\n",
    "         list(\n",
    "             zip(execution_times.values(), [execution_times[1] * x for x in execution_times.keys()],\n",
    "                 [execution_times[1] for _ in execution_times.keys()])),\n",
    "         label=[\"actual\", \"serial\", \"parallel\"])\n",
    "plt.legend()\n",
    "\n",
    "# function to show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66334a9",
   "metadata": {},
   "source": [
    "### 3.3 - Event Driven Pipeline: Creating a Microservice\n",
    "\n",
    "In a true production environment, the CVE scans would be triggered by some other event, such as a new container being uploaded into a registry or a new project being created. In this section, we will show how to create a microservice that can be triggered by an event and run the pipeline we built in the previous sections.\n",
    "\n",
    "Previously, when our pipeline was started, it would read all inputs from a DataFrame and run the pipeline for each input. Once the pipeline was done processing the DataFrame, it would shutdown. To run the pipeline as a microservice, we need to modify the pipeline to run continuously and listen for new inputs on an HTTP endpoint.\n",
    "\n",
    "Fortunately, in Morpheus this is as easy as changing out the type of source that is used in the pipeline. The code below is identical to the previous pipeline except we have changed the source from `InMemorySourceStage` to `HttpServerSourceStage`. The `HttpServerSourceStage` class listens for new inputs on an HTTP endpoint and passes them to the next stage in the pipeline. It pulls the inputs from the request body and passes them to the pipeline to be processed.\n",
    "\n",
    "Additionally, right after the `HttpServerSourceStage` we have added a simple custom stage to the pipeline `print_payload`. This custom stage simply prints the payload that was passed to the pipeline. This is useful for debugging and seeing exactly when the pipeline was triggered since the results may take time to process and be shown to the console.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca8d4182",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code for creating a microservice\n",
    "from cyber_dev_day.pipeline_utils import build_cve_llm_engine\n",
    "\n",
    "from morpheus.messages import ControlMessage\n",
    "from morpheus.messages import MessageMeta\n",
    "from morpheus.pipeline.linear_pipeline import LinearPipeline\n",
    "from morpheus.pipeline.stage_decorator import stage\n",
    "from morpheus.stages.input.http_server_source_stage import HttpServerSourceStage\n",
    "from morpheus.stages.llm.llm_engine_stage import LLMEngineStage\n",
    "from morpheus.stages.output.in_memory_sink_stage import InMemorySinkStage\n",
    "from morpheus.stages.preprocess.deserialize_stage import DeserializeStage\n",
    "from morpheus.utils.concat_df import concat_dataframes\n",
    "from morpheus.utils.http_utils import HTTPMethod\n",
    "\n",
    "\n",
    "async def run_cve_pipeline_microservice(p_config: Config, e_config: EngineConfig):\n",
    "\n",
    "    completion_task = {\"task_type\": \"completion\", \"task_dict\": {\"input_keys\": [\"cve_info\"], }}\n",
    "\n",
    "    pipe = LinearPipeline(p_config)\n",
    "\n",
    "    # Use an HTTP source to listed for requests. The expected payload is:\n",
    "    # [{\"cve_info\": <sting>},\n",
    "    #  {\"cve_info\": <sting>},]\n",
    "    pipe.set_source(\n",
    "        HttpServerSourceStage(p_config, bind_address=\"0.0.0.0\", port=26302, endpoint=\"/scan\", method=HTTPMethod.POST))\n",
    "\n",
    "    # To see when our pipeline has been triggered, add a simple logging stage to print the payload\n",
    "    @stage\n",
    "    def print_payload(payload: MessageMeta) -> MessageMeta:\n",
    "        serialized_str = payload.df.to_json(orient='records', lines=True)\n",
    "\n",
    "        logger.info(\"======= Got Request =======\\n%s\\n===========================\", serialized_str)\n",
    "\n",
    "        return payload\n",
    "\n",
    "    pipe.add_stage(print_payload(config=p_config))\n",
    "\n",
    "    # The remaineder of the pipeline is identical to the previous example\n",
    "    pipe.add_stage(\n",
    "        DeserializeStage(p_config, message_type=ControlMessage, task_type=\"llm_engine\", task_payload=completion_task))\n",
    "\n",
    "    pipe.add_stage(LLMEngineStage(p_config, engine=build_cve_llm_engine(e_config)))\n",
    "\n",
    "    sink = pipe.add_stage(InMemorySinkStage(p_config))\n",
    "\n",
    "    await pipe.run_async()\n",
    "\n",
    "    messages = sink.get_messages()\n",
    "    responses = concat_dataframes(messages)\n",
    "\n",
    "    logger.info(\"Pipeline complete\")\n",
    "\n",
    "    logger.info(\"Pipeline complete. Received %s responses:\\n%s\", len(messages), responses['response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ababebfe",
   "metadata": {},
   "source": [
    "Finally, we can start our microservice by running the pipeline as we have in the past. While the pipeline is running, move on to the next section to see how to trigger the pipeline with an HTTP request.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> When executed, the following cell will run indefinitely. You will need to interrupt the kernel to stop it. \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f4f87ac9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Pipeline Pre-build====\n",
      "====Pre-Building Segment: linear_segment_0====\n",
      "====Pre-Building Segment Complete!====\n",
      "====Pipeline Pre-build Complete!====\n",
      "====Registering Pipeline====\n",
      "====Building Pipeline====\n",
      "====Building Pipeline Complete!====\n",
      "====Registering Pipeline Complete!====\n",
      "====Starting Pipeline====\n",
      "====Pipeline Started====\n",
      "====Building Segment: linear_segment_0====\n",
      "Added source: <from-http-37; HttpServerSourceStage(bind_address=0.0.0.0, port=26302, endpoint=/scan, method=HTTPMethod.POST, accept_status=201, sleep_time=0.1, queue_timeout=5, max_queue_size=None, num_server_threads=None, max_payload_size=10, request_timeout_secs=30, lines=False, stop_after=0)>\n",
      "  â””â”€> morpheus.MessageMeta\n",
      "Added stage: <print_payload-38; WrappedFunctionStage(name=print_payload, on_data_fn=functools.partial(<function run_cve_pipeline_microservice.<locals>.print_payload at 0x7f71e4127370>), accept_type=<class 'morpheus.messages.message_meta.MessageMeta'>, compute_schema_fn=<function stage.<locals>.wrapper.<locals>.compute_schema_fn at 0x7f71e4127490>, needed_columns=None)>\n",
      "  â””â”€ morpheus.MessageMeta -> morpheus.MessageMeta\n",
      "Added stage: <deserialize-39; DeserializeStage(ensure_sliceable_index=True, message_type=<class 'morpheus._lib.messages.ControlMessage'>, task_type=llm_engine, task_payload={'task_type': 'completion', 'task_dict': {'input_keys': ['cve_info']}})>\n",
      "  â””â”€ morpheus.MessageMeta -> morpheus.ControlMessage\n",
      "Added stage: <llm-engine-40; LLMEngineStage(engine=<morpheus._lib.llm.LLMEngine object at 0x7f71e453e5f0>)>\n",
      "  â””â”€ morpheus.ControlMessage -> morpheus.ControlMessage\n",
      "Added stage: <to-mem-41; InMemorySinkStage()>\n",
      "  â””â”€ morpheus.ControlMessage -> morpheus.ControlMessage\n",
      "====Building Segment Complete!====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I20240315 17:50:28.699340  2768 asyncio_runnable.hpp:246] AsyncioRunnable::run() > Creating new event loop\n",
      "I20240315 17:50:28.700188  2768 asyncio_runnable.hpp:259] AsyncioRunnable::run() > Calling run_until_complete() on main_task()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Got Request =======\n",
      "{\"cve_info\":\"An issue was discovered in the Linux kernel through 6.0.9. drivers\\/media\\/dvb-core\\/dvbdev.c has a use-after-free, related to dvb_register_device dynamically allocating fops.\"}\n",
      "\n",
      "===========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_407/2223737218.py:31: DeprecationWarning: Warning the df property returns a copy, please use the copy_dataframe method or the mutable_dataframe context manager to modify the DataFrame in-place instead.\n",
      "  serialized_str = payload.df.to_json(orient='records', lines=True)\n",
      "/opt/conda/envs/morpheus/lib/python3.10/site-packages/cudf/io/json.py:239: UserWarning: Using CPU via Pandas to write JSON dataset\n",
      "  warnings.warn(\"Using CPU via Pandas to write JSON dataset\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to check if the Docker container's Linux kernel has the mentioned use-after-free vulnerability in the specified file and function. To do this, I can first use the SBOM Package Checker to see if the Linux kernel is present in the container and get its version number. Then, I can use the Docker Container Code QA System to check if the container's Linux kernel uses the problematic function in the given file.\n",
      "\n",
      "Action: SBOM Package Checker\n",
      "Action Input: Linux kernel\n",
      "\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe package Linux kernel\n",
      "\n",
      " was not found in the SBOM\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mIt seems that the SBOM Package Checker did not find the Linux kernel in the Docker container. This might be because the container is using a custom-built kernel or the SBOM is not complete. In any case, without knowing the kernel version, it's impossible to determine if the use-after-free vulnerability is present. I would recommend further investigation into why the Linux kernel is not present in the SBOM or checking if there's an alternative way to determine the kernel version.\n",
      "\n",
      "Final Answer: I cannot determine if the Docker container's Linux kernel has the mentioned use-after-free vulnerability in the specified file and function due to the Linux kernel not being present in the SBOM.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "======= Got Request =======\n",
      "{\"cve_info\":\"An issue in the urllib.parse component of Python before 3.11.4 allows attackers to bypass blocklisting methods by supplying a URL that starts with blank characters.\"}\n",
      "\n",
      "===========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_407/2223737218.py:31: DeprecationWarning: Warning the df property returns a copy, please use the copy_dataframe method or the mutable_dataframe context manager to modify the DataFrame in-place instead.\n",
      "  serialized_str = payload.df.to_json(orient='records', lines=True)\n",
      "/opt/conda/envs/morpheus/lib/python3.10/site-packages/cudf/io/json.py:239: UserWarning: Using CPU via Pandas to write JSON dataset\n",
      "  warnings.warn(\"Using CPU via Pandas to write JSON dataset\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to check if the Docker container's Python version is affected by this vulnerability. To do this, I'll first use the SBOM Package Checker to see if the container has Python installed and determine its version. If the container does have Python and its version is before 3.11.4, then it might be vulnerable. However, to confirm the vulnerability, I would need to analyze the application code using the Docker Container Code QA System to see if it uses the urllib.parse component and if it accepts URLs starting with blank characters.\n",
      "\n",
      "Action: SBOM Package Checker\n",
      "Action Input: Python\n",
      "\n",
      "(Waiting for the SBOM Package Checker to return the result)\n",
      "\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe package Python\n",
      "\n",
      "(Waiting for the SBOM Package Checker to return the result)\n",
      "\n",
      " was not found in the SBOM\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mSince the SBOM Package Checker did not find the Python package in the Docker container, I cannot determine the Python version installed in the container. Therefore, I cannot confirm if the Docker container is vulnerable to the urllib.parse component vulnerability in Python before 3.11.4.\n",
      "\n",
      "Final Answer: I cannot confirm if the Docker container is vulnerable to the urllib.parse component vulnerability in Python before 3.11.4 as the Python package was not found in the SBOM.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Stopping pipeline. Please wait... Press Ctrl+C again to kill.\n",
      "====Stopping Pipeline====\n",
      "====Pipeline Stopped====\n",
      "====Pipeline Complete====\n",
      "Pipeline complete\n",
      "Pipeline complete. Received 2 responses:\n",
      "\"\"\n",
      "0    I cannot determine if the Docker container's Linux kernel has the mentioned use-after-free vulnerability in the specified file and function due to the Linux kernel not being present in the SBOM.\n",
      "0                           I cannot confirm if the Docker container is vulnerable to the urllib.parse component vulnerability in Python before 3.11.4 as the Python package was not found in the SBOM.\n",
      "Name: response, dtype: object\n",
      "Killing\n"
     ]
    }
   ],
   "source": [
    "await run_cve_pipeline_microservice(pipeline_config, engine_config_custom_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb51d69",
   "metadata": {},
   "source": [
    "#### 3.3.1 - Triggering the Microservice\n",
    "\n",
    "To trigger the microservice, we will use a CURL request to send a request to the microservice. Since the notebook cannot run commands while the microservice is running, we need to open up a new terminal to send the request. To do that, follow the steps below:\n",
    "\n",
    "1. In Jupyter Lab, press Ctrl + Shift + L (Shift + âŒ˜ + L on Mac) to open a new Launcher tab\n",
    "2. In the Launcher tab, click on the Terminal icon to open a new terminal\n",
    "3. In the terminal, run the following command to send a request to the microservice:\n",
    "\n",
    "```bash\n",
    "curl --request POST \\\n",
    "  --url http://localhost:26302/scan \\\n",
    "  --header 'Content-Type: application/json' \\\n",
    "  --data '[{\n",
    "      \"cve_info\" : \"An issue was discovered in the Linux kernel through 6.0.9. drivers/media/dvb-core/dvbdev.c has a use-after-free, related to dvb_register_device dynamically allocating fops.\"\n",
    "   }]'\n",
    "```\n",
    "\n",
    "4. Once the request is sent, the microservice will process the request and return the results in the terminal\n",
    "   1. To see the results, switch back to the Notebook tab. You should see that the microservice received your request and started processing it.\n",
    "   ```\n",
    "   I20240308 16:00:56.422039 3010283 http_server.cpp:129] Received request: POST : /scan\n",
    "   ```\n",
    "   2. It helps to have the terminal and the notebook side by side so you can see the results in the terminal as they come in. To do this, click on the terminal tab and drag it to the right side of the screen. You should then be able to see the terminal and the notebook side by side similar to the image below:\n",
    "      ![Terminal and Notebook Side by Side](./images/side_by_side.png)\n",
    "5. To stop the microservice, interrupt the kernel by pressing the stop button in the toolbar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe6e684",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
