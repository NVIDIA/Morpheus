{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2941e94f-db20-44a5-ab87-2cab499825f7",
   "metadata": {},
   "source": [
    "# Digital Finger Printing (DFP) with Morpheus - Azure Integrated Training\n",
    "## Introduction\n",
    "\n",
    "In this notebook, we will be building and running a DFP pipeline that performs both training and inference on Azure-AD logs. The goal is to train an autoencoder PyTorch model to recogize the patterns of users in the sample data. The model will then be used by another fork (inference) in the pipeline to generate anomaly scores for each individual log. These anomaly scores can be used by security teams to detect abnormal behavior when it happens so the proper action can be taken.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> For more information on DFP, the Morpheus pipeline, and setup steps to run this notebook, please refer to the coresponding DFP integrated training materials.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6c1cb50-74f2-445d-b865-8c22c3b3798b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Ensure that the morpheus directory is in the python path. This may not need to be run depending on the environment setup\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(\"../../morpheus\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "102ce011-3ca3-4f96-a72d-de28fad32003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/morpheus/lib/python3.10/site-packages/merlin/dtypes/mappings/tf.py:52: UserWarning: Tensorflow dtype mappings did not load successfully due to an error: No module named 'tensorflow'\n",
      "  warn(f\"Tensorflow dtype mappings did not load successfully due to an error: {exc.msg}\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>table {align:left;display:block}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "import typing\n",
    "import cudf\n",
    "from datetime import datetime\n",
    "\n",
    "# When segment modules are imported, they're added to the module registry. \n",
    "# To avoid flake8 warnings about unused code, the noqa flag is used during import.\n",
    "import dfp.modules  # noqa: F401\n",
    "from dfp.utils.config_generator import ConfigGenerator\n",
    "from dfp.utils.config_generator import generate_ae_config\n",
    "from dfp.utils.dfp_arg_parser import DFPArgParser\n",
    "from dfp.utils.schema_utils import Schema\n",
    "from dfp.utils.schema_utils import SchemaBuilder\n",
    "\n",
    "import morpheus.loaders  # noqa: F401\n",
    "import morpheus.modules  # noqa: F401\n",
    "from morpheus.config import Config\n",
    "from morpheus.pipeline.pipeline import Pipeline\n",
    "from morpheus.stages.general.monitor_stage import MonitorStage\n",
    "from morpheus.stages.general.multi_port_modules_stage import MultiPortModulesStage\n",
    "from morpheus.stages.input.control_message_file_source_stage import ControlMessageFileSourceStage\n",
    "\n",
    "# Left align all tables\n",
    "from IPython.core.display import HTML\n",
    "table_css = 'table {align:left;display:block}'\n",
    "HTML('<style>{}</style>'.format(table_css))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca38c1b7-ce84-43e0-ac53-280562dc1642",
   "metadata": {},
   "source": [
    "## High Level Configuration\n",
    "\n",
    "The pipeline's functionality can be significantly altered by the following options, which are utilized across the entire pipeline. However, module-specific options also exist. The matching Python script for this notebook, `dfp_integrated_training_batch_pipeline.py`, configures these options through command line arguments.\n",
    "\n",
    "### Options\n",
    "\n",
    "| Name                   | Type                                       | Description                                                                                                                                                                                                                                                                            | Default Value |\n",
    "|------------------------|--------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------|\n",
    "| `source`            | One of `[\"duo\", \"azure\"]`           | Indicates what type of logs are going to be used in the workload.                                                                                                                                                                                                            | -             |\n",
    "| `train_users`    | One of `[\"all\", \"generic\", \"individual\"]` | Indicates whether or not to train per user or a generic model for all users. Selecting none runs the inference pipeline.                                                                                                                                                                    | -             |\n",
    "| `skip_user`        | List of strings                                       | User IDs to skip. Mutually exclusive with `only_user`.                                                                                                                                                                                                                                               | -             |\n",
    "| `only_user`        | List of strings                                       | Only users specified by this option will be included. Mutually exclusive with `skip_user`.                                                                                                                                                                                                 | -             |\n",
    "| `start_time`       | `str`                                         | The start of the time window, if undefined start_date will be `now()-duration`.                                                                                                                                                                                                  | -             |\n",
    "| `duration`         | `str`                                         | The training duration to run starting from `start_time`.                                                                                                                                                                                                                                              | -             |\n",
    "| `cache_dir`        | `str`                                         | The location to cache data such as S3 downloads and pre-processed data.                                                                                                                                                                                                                    | -             |\n",
    "| `log_level`        | `str`                                         | Specify the logging level to use.                                                                                                                                                                                                                                                                    | `info`        |\n",
    "| `sample_rate_s`    | `int`                                         | Minimum time step, in milliseconds, between object logs.                                                                                                                                                                                                                                           | `0`        |\n",
    "| `silence_monitors`    | `bool`                                         | Controls whether monitors will be verbose logs.                                                                                                                                                                                                                                           | `False`        |\n",
    "| `tracking_uri`     | `str`                                         | The MLflow tracking URI to connect to the tracking backend.                                                                                                                                                                                                                                    | -             |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ee00703-75c5-46fc-890c-86733da906c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source\n",
    "source = \"azure\"\n",
    "\n",
    "# Global options\n",
    "train_users = \"all\"\n",
    "\n",
    "# Start time\n",
    "start_time = datetime.strptime(\"2022-08-01\", \"%Y-%m-%d\")\n",
    "\n",
    "# Duration\n",
    "duration = \"60d\"\n",
    "\n",
    "# Smaple rate secs\n",
    "sample_rate_s = 0\n",
    "\n",
    "# MLFLow tracking uri\n",
    "tracking_uri = \"http://mlflow:5000\"\n",
    "\n",
    "# Enter any users to skip here\n",
    "skip_user: typing.List[str] = []\n",
    "\n",
    "# Only users\n",
    "only_user: typing.List[str] = []\n",
    "\n",
    "# Setting Log level\n",
    "log_level = logging.INFO\n",
    "\n",
    "# Location where cache objects will be saved\n",
    "cache_dir = \"./.cache/dfp\"\n",
    "\n",
    "# Silence monitors\n",
    "silence_monitors = True\n",
    "\n",
    "# Control messages as input files\n",
    "load_train_only_input_files = [\n",
    "    \"./resource/azure_payload_lt.json\"\n",
    "]\n",
    "load_train_inference_input_files = [\n",
    "    \"./resource/azure_payload_lti.json\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f80a19",
   "metadata": {},
   "source": [
    "### Arguments Parser\n",
    "\n",
    "The [DFPArgParser](../../../production/morpheus/dfp/utils/dfp_arg_parser.py) class is used for parsing and storing arguments used in a  pipeline for training, generating models and inference. It has several properties and methods to transform, store and access the arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f5b67b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_arg_parser = DFPArgParser(\n",
    "    skip_user,\n",
    "    only_user,\n",
    "    start_time,\n",
    "    log_level,\n",
    "    cache_dir,\n",
    "    sample_rate_s,\n",
    "    duration,\n",
    "    source,\n",
    "    tracking_uri,\n",
    "    silence_monitors,\n",
    "    train_users\n",
    ")\n",
    "\n",
    "# Initalize parser\n",
    "dfp_arg_parser.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01abd537-9162-49dc-8e83-d9465592f1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create global config object for the pipeline\n",
    "config: Config = generate_ae_config(\n",
    "    source,\n",
    "    userid_column_name=\"username\",\n",
    "    timestamp_column_name=\"timestamp\",\n",
    "    use_cpp=True,\n",
    ")\n",
    "\n",
    "# Construct the dataframe Schema which is used to normalize incoming azure logs\n",
    "schema_builder = SchemaBuilder(config, source)\n",
    "schema: Schema = schema_builder.build_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb42888",
   "metadata": {},
   "source": [
    "### DFP Deployment Module Configuration\n",
    "This module sets up modular Digital Fingerprinting intergated training pipeline instance.\n",
    "\n",
    "### Configurable Parameters\n",
    "\n",
    "| Parameter           | Type | Description                               | Example Value | Default Value |\n",
    "|---------------------|------|-------------------------------------------|---------------|---------------|\n",
    "| `inference_options` | dict | Options for the inference pipeline module | See Below     | `[Required]`  |\n",
    "| `training_options`  | dict | Options for the training pipeline module  | See Below     | `[Required]`  |\n",
    "\n",
    "### Training Options Parameters\n",
    "\n",
    "| Parameter                    | Type | Description                                    | Example Value        | Default Value |\n",
    "|------------------------------|------|------------------------------------------------|----------------------|---------------|\n",
    "| `batching_options`           | dict | Options for batching the data                  | See Below            | `-`           |\n",
    "| `cache_dir`                  | str  | Directory to cache the rolling window data     | \"/path/to/cache/dir\" | `./.cache`    |\n",
    "| `dfencoder_options`          | dict | Options for configuring the data frame encoder | See Below            | `-`           |\n",
    "| `mlflow_writer_options`      | dict | Options for the MLflow model writer            | See Below            | `-`           |\n",
    "| `preprocessing_options`      | dict | Options for preprocessing the data             | See Below            | `-`           |\n",
    "| `stream_aggregation_options` | dict | Options for aggregating the data by stream     | See Below            | `-`           |\n",
    "| `timestamp_column_name`      | str  | Name of the timestamp column used in the data  | \"my_timestamp\"       | `timestamp`   |\n",
    "| `user_splitting_options`     | dict | Options for splitting the data by user         | See Below            | `-`           |\n",
    "\n",
    "### Inference Options Parameters\n",
    "\n",
    "| Parameter                    | Type | Description                                    | Example Value        | Default Value  |\n",
    "|------------------------------|------|------------------------------------------------|----------------------|----------------|\n",
    "| `batching_options`           | dict | Options for batching the data                  | See Below            | `-`            |\n",
    "| `cache_dir`                  | str  | Directory to cache the rolling window data     | \"/path/to/cache/dir\" | `./.cache`     |\n",
    "| `detection_criteria`         | dict | Criteria for filtering detections              | See Below            | `-`            |\n",
    "| `fallback_username`          | str  | User ID to use if user ID not found            | \"generic_user\"       | `generic_user` |\n",
    "| `inference_options`          | dict | Options for the inference module               | See Below            | `-`            |\n",
    "| `model_name_formatter`       | str  | Format string for the model name               | \"model_{timestamp}\"  | `[Required]`   |\n",
    "| `num_output_ports`           | int  | Number of output ports for the module          | 3                    | `-`            |\n",
    "| `timestamp_column_name`      | str  | Name of the timestamp column in the input data | \"timestamp\"          | `timestamp`    |\n",
    "| `stream_aggregation_options` | dict | Options for aggregating the data by stream     | See Below            | `-`            |\n",
    "| `user_splitting_options`     | dict | Options for splitting the data by user         | See Below            | `-`            |\n",
    "| `write_to_file_options`      | dict | Options for writing the detections to a file   | See Below            | `-`            |\n",
    "\n",
    "### `batching_options`\n",
    "\n",
    "| Key                      | Type            | Description                         | Example Value                               | Default Value              |\n",
    "|--------------------------|-----------------|-------------------------------------|---------------------------------------------|----------------------------|\n",
    "| `end_time`               | datetime/string | Endtime of the time window          | \"2023-03-14T23:59:59\"                       | `None`                     |\n",
    "| `iso_date_regex_pattern` | string          | Regex pattern for ISO date matching | \"\\\\d{4}-\\\\d{2}-\\\\d{2}T\\\\d{2}:\\\\d{2}:\\\\d{2}\" | `<iso_date_regex_pattern>` |\n",
    "| `parser_kwargs`          | dictionary      | Additional arguments for the parser | {}                                          | `{}`                       |\n",
    "| `period`                 | string          | Time period for grouping files      | \"1d\"                                        | `D`                        |\n",
    "| `sampling_rate_s`        | integer         | Sampling rate in seconds            | 0                                          | `None`                       |\n",
    "| `start_time`             | datetime/string | Start time of the time window       | \"2023-03-01T00:00:00\"                       | `None`                     |\n",
    "\n",
    "### `dfencoder_options`\n",
    "\n",
    "| Parameter         | Type  | Description                            | Example Value                                                                                                                                                                                                                                                 | Default Value |\n",
    "|-------------------|-------|----------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------|\n",
    "| `feature_columns` | list  | List of feature columns to train on    | [\"column1\", \"column2\", \"column3\"]                                                                                                                                                                                                                             | `-`           |\n",
    "| `epochs`          | int   | Number of epochs to train for          | 50                                                                                                                                                                                                                                                            | `-`           |\n",
    "| `model_kwargs`    | dict  | Keyword arguments to pass to the model | {\"encoder_layers\": [64, 32], \"decoder_layers\": [32, 64], \"activation\": \"relu\", \"swap_p\": 0.1, \"lr\": 0.001, \"lr_decay\": 0.9, \"batch_size\": 32, \"verbose\": 1, \"optimizer\": \"adam\", \"scalar\": \"min_max\", \"min_cats\": 10, \"progress_bar\": false, \"device\": \"cpu\"} | `-`           |\n",
    "| `validation_size` | float | Size of the validation set             | 0.1                                                                                                                                                                                                                                                           | `-`           |\n",
    "\n",
    "### `monitor_options`\n",
    "\n",
    "| Key                          | Type    | Description                                                | Example Value | Default Value |\n",
    "| ----------------------------|---------|------------------------------------------------------------|---------------|---------------|\n",
    "| `description`               | string  | Name to show for this Monitor Stage in the console window  | \"Progress\"    | `Progress`    |\n",
    "| `silence_monitors`          | bool    | Silence the monitors on the console                        | See Below     | `None`        |\n",
    "| `smoothing`                 | float   | Smoothing parameter to determine how much the throughput should be averaged | 0.01 | `0.05` |\n",
    "| `unit`                      | string  | Units to show in the rate value                             | \"messages\"    | `messages`    |\n",
    "| `delayed_start`             | bool    | When delayed_start is enabled, the progress bar will not be shown until the first message is received. Otherwise, the progress bar is shown on pipeline startup and will begin timing immediately. In large pipelines, this option may be desired to give a more accurate timing. | True  | `False`   |\n",
    "| `determine_count_fn_schema` | string  | Custom function for determining the count in a message      | \"Progress\"    | `Progress`    |\n",
    "| `log_level`                 | string  | Enable this stage when the configured log level is at `log_level` or lower. | \"DEBUG\" | `INFO` |\n",
    "\n",
    "\n",
    "### `mlflow_writer_options`\n",
    "\n",
    "| Key                         | Type       | Description                       | Example Value                 | Default Value |\n",
    "|-----------------------------|------------|-----------------------------------|-------------------------------|---------------|\n",
    "| `conda_env`                 | string     | Conda environment for the model   | \"path/to/conda_env.yml\"       | `[Required]`  |\n",
    "| `databricks_permissions`    | dictionary | Permissions for the model         | See Below                     | `None`        |\n",
    "| `experiment_name_formatter` | string     | Formatter for the experiment name | \"experiment_name_{timestamp}\" | `[Required]`  |\n",
    "| `model_name_formatter`      | string     | Formatter for the model name      | \"model_name_{timestamp}\"      | `[Required]`  |\n",
    "| `timestamp_column_name`     | string     | Name of the timestamp column      | \"timestamp\"                   | `timestamp`   |\n",
    "\n",
    "### `stream_aggregation_options`\n",
    "\n",
    "| Parameter               | Type   | Description                                                 | Example Value | Default Value |\n",
    "|-------------------------|--------|-------------------------------------------------------------|---------------|---------------|\n",
    "| `cache_mode`            | string | The user ID to use if the user ID is not found              | \"batch\"       | `batch`       |\n",
    "| `min_history`           | int    | Minimum history to trigger a new training event             | 1             | `1`           |\n",
    "| `max_history`           | int    | Maximum history to include in a new training event          | 0             | `0`           |\n",
    "| `timestamp_column_name` | string | Name of the column containing timestamps                    | \"timestamp\"   | `timestamp`   |\n",
    "| `aggregation_span`      | string | Lookback timespan for training data in a new training event | \"60d\"         | `60d`         |\n",
    "| `cache_to_disk`         | bool   | Whether or not to cache streaming data to disk              | false         | `false`       |\n",
    "| `cache_dir`             | string | Directory to use for caching streaming data                 | \"./.cache\"    | `./.cache`    |\n",
    "\n",
    "### `user_splitting_options`\n",
    "\n",
    "| Key                     | Type | Description                                          | Example Value               | Default Value  |\n",
    "|-------------------------|------|------------------------------------------------------|-----------------------------|----------------|\n",
    "| `fallback_username`     | str  | The user ID to use if the user ID is not found       | \"generic_user\"              | `generic_user` |\n",
    "| `include_generic`       | bool | Whether to include a generic user ID in the output   | false                       | `false`        |\n",
    "| `include_individual`    | bool | Whether to include individual user IDs in the output | true                        | `false`        |\n",
    "| `only_users`            | list | List of user IDs to include; others will be excluded | [\"user1\", \"user2\", \"user3\"] | `[]`           |\n",
    "| `skip_users`            | list | List of user IDs to exclude from the output          | [\"user4\", \"user5\"]          | `[]`           |\n",
    "| `timestamp_column_name` | str  | Name of the column containing timestamps             | \"timestamp\"                 | `timestamp`    |\n",
    "| `userid_column_name`    | str  | Name of the column containing user IDs               | \"username\"                  | `username`     |\n",
    "\n",
    "### `detection_criteria`\n",
    "\n",
    "| Key          | Type  | Description                              | Example Value | Default Value |\n",
    "|--------------|-------|------------------------------------------|---------------|---------------|\n",
    "| `threshold`  | float | Threshold for filtering detections       | 0.5           | `0.5`         |\n",
    "| `field_name` | str   | Name of the field to filter by threshold | \"score\"       | `probs`       |\n",
    "\n",
    "### `inference_options`\n",
    "\n",
    "| Parameter               | Type   | Description                                          | Example Value           | Default Value |\n",
    "|-------------------------|--------|------------------------------------------------------|-------------------------|---------------|\n",
    "| `model_name_formatter`  | string | Formatter for model names                            | \"user_{username}_model\" | `[Required]`  |\n",
    "| `fallback_username`     | string | Fallback user to use if no model is found for a user | \"generic_user\"          | `generic_user`|\n",
    "| `timestamp_column_name` | string | Name of the timestamp column                         | \"timestamp\"             | `timestamp`   |\n",
    "\n",
    "### `write_to_file_options`\n",
    "\n",
    "| Key                 | Type      | Description                              | Example Value   | Default Value    |\n",
    "|---------------------|-----------|------------------------------------------|-----------------|------------------|\n",
    "| `filename`          | string    | Path to the output file                  | \"output.csv\"    | `None`           |\n",
    "| `file_type`         | string    | Type of file to write                    | \"CSV\"           | `AUTO`           |\n",
    "| `flush`             | bool      | If true, flush the file after each write | false           | `false`          |\n",
    "| `include_index_col` | bool      | If true, include the index column        | false           | `true`           |\n",
    "| `overwrite`         | bool      | If true, overwrite the file if it exists | true            | `false`          |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a73a4d53-32b6-4ab8-a5d7-c0104b31c69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create config helper is used to generate config parameters for the DFP module\n",
    "# This will populate to the minimum configuration parameters with intelligent default values\n",
    "config_generator = ConfigGenerator(config, dfp_arg_parser, schema)\n",
    "\n",
    "dfp_deployment_module_config = config_generator.get_module_conf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfc59de-dea8-4e5f-98e3-98eba1e4621d",
   "metadata": {},
   "source": [
    "## Pipeline Construction\n",
    "From this point on we begin constructing the stages that will make up the pipeline. To make testing easier, constructing the pipeline object, adding the stages, and running the pipeline, is provided as a single cell. The below cell can be rerun multiple times as needed for debugging.\n",
    "\n",
    "### Source Stage (`ControlMessageFileSourceStage`)\n",
    "\n",
    "This pipeline read control message definations from one or more input files. This source stage will constructs control message and pass to downstream stages. It is capable of reading files from many different source types, both local and remote. This is possible by utilizing the `fsspec` library (similar to `pandas`). Refer to the [`fsspec`](https://filesystem-spec.readthedocs.io/) documentation for more information on the supported file types. Once all of the logs have been read, the source completes. \n",
    "\n",
    "| Name | Type | Default | Description |\n",
    "| --- | --- | --- | :-- |\n",
    "| `filenames` | List of strings | | Any control message defination files to read into the pipeline |\n",
    "\n",
    "### DFP Deployment Module (`MultiPortModulesStage`)\n",
    "\n",
    "MultiPortModulesStage is used to load modules that returns more than one ouptut. DFP deployment module sets up modular Digital Fingerprinting Pipeline instance. and performs integrated training as shown in the below diagram. For more information on the options passed to this module is shown [here](../../../../../docs/source/modules/examples/digital_fingerprinting/dfp_deployment.md).\n",
    "\n",
    "\n",
    "## End-to-End Workflow Architecture\n",
    "\n",
    "![Integrated Training Pipeline](../../../../../docs/source/img/dfp_integrated_training_file_pipeline.png))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "825390ad-ce64-4949-b324-33039ffdf264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_pipeline(input_files: list[str]):\n",
    "    # Create a pipeline object\n",
    "    pipeline = Pipeline(config)\n",
    "\n",
    "    # ControlMessage file source stage.\n",
    "    source_stage = pipeline.add_stage(ControlMessageFileSourceStage(config, filenames=input_files))\n",
    "\n",
    "    # DFP deployment (integrated training) module stage.\n",
    "    dfp_deployment_stage = pipeline.add_stage(\n",
    "        MultiPortModulesStage(config,\n",
    "                                dfp_deployment_module_config,\n",
    "                                input_ports=[\"input\"],\n",
    "                                output_ports=[\"output_0\", \"output_1\"]))\n",
    "\n",
    "    # Connect stages with edges.\n",
    "    pipeline.add_edge(source_stage, dfp_deployment_stage)\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4b93cb",
   "metadata": {},
   "source": [
    "### Training\n",
    "To ensure a smooth deployment of the inference tasks to the pipeline, it is imperative to have at least one version of the trained model available on the MLflow server. Once the initial model training is complete, we can proceed with the publishing of the inference tasks to the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0061d502",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files = load_train_only_input_files\n",
    "\n",
    "pipeline = construct_pipeline(input_files)\n",
    "await pipeline.run_async()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1472a0",
   "metadata": {},
   "source": [
    "### Training and Inference\n",
    "Now that we have a trained model available in MLflow, we can begin executing both training and inference tasks in parallel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64339676",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files = load_train_inference_input_files\n",
    "\n",
    "pipeline = construct_pipeline(input_files)\n",
    "await pipeline.run_async()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24caa6f",
   "metadata": {},
   "source": [
    "### Inference Results\n",
    "Pipeline writes the inference results to `dfp_detections_azure.csv` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "960f14ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>username</th>\n",
       "      <th>appDisplayName</th>\n",
       "      <th>clientAppUsed</th>\n",
       "      <th>deviceDetailbrowser</th>\n",
       "      <th>deviceDetaildisplayName</th>\n",
       "      <th>deviceDetailoperatingSystem</th>\n",
       "      <th>statusfailureReason</th>\n",
       "      <th>logcount</th>\n",
       "      <th>...</th>\n",
       "      <th>locincrement_loss</th>\n",
       "      <th>logcount_z_loss</th>\n",
       "      <th>clientAppUsed_pred</th>\n",
       "      <th>clientAppUsed_loss</th>\n",
       "      <th>appDisplayName_loss</th>\n",
       "      <th>statusfailureReason_loss</th>\n",
       "      <th>appincrement_loss</th>\n",
       "      <th>appDisplayName_z_loss</th>\n",
       "      <th>model_version</th>\n",
       "      <th>event_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>2022-08-30T08:31:49.739107000Z</td>\n",
       "      <td>tprice@domain.com</td>\n",
       "      <td>SD ECDN</td>\n",
       "      <td>Browser</td>\n",
       "      <td>Rich Client 3.19.8.16603</td>\n",
       "      <td>THOMASPRICE-LT</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.610670</td>\n",
       "      <td>0.027359</td>\n",
       "      <td>Mobile Apps and Desktop clients</td>\n",
       "      <td>1.174857</td>\n",
       "      <td>2.780367</td>\n",
       "      <td>1.605560</td>\n",
       "      <td>0.735984</td>\n",
       "      <td>1.979742</td>\n",
       "      <td>DFP-azure-tprice@domain.com:1</td>\n",
       "      <td>2023-07-20T20:24:22Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>2022-08-31T00:21:46.153050000Z</td>\n",
       "      <td>attacktarget@domain.com</td>\n",
       "      <td>Citrix ShareFile</td>\n",
       "      <td>Mobile Apps and Desktop clients</td>\n",
       "      <td>Chrome 100.0.4896</td>\n",
       "      <td>ATTACKTARGET-LT</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.914863</td>\n",
       "      <td>0.633756</td>\n",
       "      <td>Mobile Apps and Desktop clients</td>\n",
       "      <td>0.591306</td>\n",
       "      <td>1.697818</td>\n",
       "      <td>0.607544</td>\n",
       "      <td>2.277889</td>\n",
       "      <td>2.968441</td>\n",
       "      <td>DFP-azure-attacktarget@domain.com:2</td>\n",
       "      <td>2023-07-20T20:25:09Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>2022-08-31T00:27:44.169328000Z</td>\n",
       "      <td>attacktarget@domain.com</td>\n",
       "      <td>Altoura</td>\n",
       "      <td>Mobile Apps and Desktop clients</td>\n",
       "      <td>Chrome 100.0.4896</td>\n",
       "      <td>ATTACKTARGET-LT</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5.936103</td>\n",
       "      <td>0.109216</td>\n",
       "      <td>Mobile Apps and Desktop clients</td>\n",
       "      <td>0.603926</td>\n",
       "      <td>1.713131</td>\n",
       "      <td>0.621300</td>\n",
       "      <td>3.988265</td>\n",
       "      <td>2.393491</td>\n",
       "      <td>DFP-azure-attacktarget@domain.com:2</td>\n",
       "      <td>2023-07-20T20:25:09Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>2022-08-31T00:44:58.235390000Z</td>\n",
       "      <td>attacktarget@domain.com</td>\n",
       "      <td>LumApps</td>\n",
       "      <td>Mobile Apps and Desktop clients</td>\n",
       "      <td>Chrome 100.0.4896</td>\n",
       "      <td>ATTACKTARGET-LT</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5.942259</td>\n",
       "      <td>0.376158</td>\n",
       "      <td>Mobile Apps and Desktop clients</td>\n",
       "      <td>0.599671</td>\n",
       "      <td>1.697026</td>\n",
       "      <td>0.614225</td>\n",
       "      <td>14.026583</td>\n",
       "      <td>2.998179</td>\n",
       "      <td>DFP-azure-attacktarget@domain.com:2</td>\n",
       "      <td>2023-07-20T20:25:09Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>2022-08-31T00:47:59.808993000Z</td>\n",
       "      <td>attacktarget@domain.com</td>\n",
       "      <td>Linux Foundation Training</td>\n",
       "      <td>Mobile Apps and Desktop clients</td>\n",
       "      <td>Chrome 100.0.4896</td>\n",
       "      <td>ATTACKTARGET-LT</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5.936529</td>\n",
       "      <td>0.562854</td>\n",
       "      <td>Mobile Apps and Desktop clients</td>\n",
       "      <td>0.589449</td>\n",
       "      <td>1.683457</td>\n",
       "      <td>0.599916</td>\n",
       "      <td>30.273712</td>\n",
       "      <td>3.507625</td>\n",
       "      <td>DFP-azure-attacktarget@domain.com:2</td>\n",
       "      <td>2023-07-20T20:25:09Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>123</td>\n",
       "      <td>2022-08-31T23:54:50.435683000Z</td>\n",
       "      <td>attacktarget@domain.com</td>\n",
       "      <td>Box</td>\n",
       "      <td>Mobile Apps and Desktop clients</td>\n",
       "      <td>Chrome 100.0.4896</td>\n",
       "      <td>ATTACKTARGET-LT</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>6.032503</td>\n",
       "      <td>2.419621</td>\n",
       "      <td>Mobile Apps and Desktop clients</td>\n",
       "      <td>0.418121</td>\n",
       "      <td>1.608195</td>\n",
       "      <td>0.420876</td>\n",
       "      <td>619.997925</td>\n",
       "      <td>6.333486</td>\n",
       "      <td>DFP-azure-attacktarget@domain.com:2</td>\n",
       "      <td>2023-07-20T20:26:07Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>312</td>\n",
       "      <td>2022-08-31T22:23:06.806213000Z</td>\n",
       "      <td>attacktarget@domain.com</td>\n",
       "      <td>Stormboard</td>\n",
       "      <td>Mobile Apps and Desktop clients</td>\n",
       "      <td>Chrome 100.0.4896</td>\n",
       "      <td>ATTACKTARGET-LT</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.503085</td>\n",
       "      <td>0.252396</td>\n",
       "      <td>Mobile Apps and Desktop clients</td>\n",
       "      <td>0.807381</td>\n",
       "      <td>4.478906</td>\n",
       "      <td>1.358579</td>\n",
       "      <td>31.562899</td>\n",
       "      <td>1.308199</td>\n",
       "      <td>DFP-azure-generic_user:53</td>\n",
       "      <td>2023-07-20T20:26:10Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>313</td>\n",
       "      <td>2022-08-31T22:43:42.029787000Z</td>\n",
       "      <td>djohnson@domain.com</td>\n",
       "      <td>Box</td>\n",
       "      <td>Mobile Apps and Desktop clients</td>\n",
       "      <td>Edge 87.11424</td>\n",
       "      <td>DAVIDJOHNSON-LT</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.514629</td>\n",
       "      <td>0.155598</td>\n",
       "      <td>Mobile Apps and Desktop clients</td>\n",
       "      <td>0.799728</td>\n",
       "      <td>4.384770</td>\n",
       "      <td>1.430044</td>\n",
       "      <td>36.937981</td>\n",
       "      <td>0.934225</td>\n",
       "      <td>DFP-azure-generic_user:53</td>\n",
       "      <td>2023-07-20T20:26:10Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>314</td>\n",
       "      <td>2022-08-31T22:43:47.300043000Z</td>\n",
       "      <td>attacktarget@domain.com</td>\n",
       "      <td>CallPlease</td>\n",
       "      <td>Mobile Apps and Desktop clients</td>\n",
       "      <td>Chrome 100.0.4896</td>\n",
       "      <td>ATTACKTARGET-LT</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.535288</td>\n",
       "      <td>0.019980</td>\n",
       "      <td>Mobile Apps and Desktop clients</td>\n",
       "      <td>0.783910</td>\n",
       "      <td>4.378347</td>\n",
       "      <td>1.345962</td>\n",
       "      <td>43.152668</td>\n",
       "      <td>0.908708</td>\n",
       "      <td>DFP-azure-generic_user:53</td>\n",
       "      <td>2023-07-20T20:26:10Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>315</td>\n",
       "      <td>2022-08-31T22:45:37.459815000Z</td>\n",
       "      <td>acole@domain.com</td>\n",
       "      <td>Foko Retail</td>\n",
       "      <td>Browser</td>\n",
       "      <td>Rich Client 4.39.0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Windows10</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507879</td>\n",
       "      <td>0.192614</td>\n",
       "      <td>Mobile Apps and Desktop clients</td>\n",
       "      <td>1.292141</td>\n",
       "      <td>4.207778</td>\n",
       "      <td>1.424070</td>\n",
       "      <td>42.751469</td>\n",
       "      <td>0.231083</td>\n",
       "      <td>DFP-azure-generic_user:53</td>\n",
       "      <td>2023-07-20T20:26:10Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                       timestamp                 username  \\\n",
       "0            10  2022-08-30T08:31:49.739107000Z        tprice@domain.com   \n",
       "1            18  2022-08-31T00:21:46.153050000Z  attacktarget@domain.com   \n",
       "2            20  2022-08-31T00:27:44.169328000Z  attacktarget@domain.com   \n",
       "3            21  2022-08-31T00:44:58.235390000Z  attacktarget@domain.com   \n",
       "4            22  2022-08-31T00:47:59.808993000Z  attacktarget@domain.com   \n",
       "..          ...                             ...                      ...   \n",
       "104         123  2022-08-31T23:54:50.435683000Z  attacktarget@domain.com   \n",
       "105         312  2022-08-31T22:23:06.806213000Z  attacktarget@domain.com   \n",
       "106         313  2022-08-31T22:43:42.029787000Z      djohnson@domain.com   \n",
       "107         314  2022-08-31T22:43:47.300043000Z  attacktarget@domain.com   \n",
       "108         315  2022-08-31T22:45:37.459815000Z         acole@domain.com   \n",
       "\n",
       "                appDisplayName                    clientAppUsed  \\\n",
       "0                      SD ECDN                          Browser   \n",
       "1             Citrix ShareFile  Mobile Apps and Desktop clients   \n",
       "2                      Altoura  Mobile Apps and Desktop clients   \n",
       "3                      LumApps  Mobile Apps and Desktop clients   \n",
       "4    Linux Foundation Training  Mobile Apps and Desktop clients   \n",
       "..                         ...                              ...   \n",
       "104                        Box  Mobile Apps and Desktop clients   \n",
       "105                 Stormboard  Mobile Apps and Desktop clients   \n",
       "106                        Box  Mobile Apps and Desktop clients   \n",
       "107                 CallPlease  Mobile Apps and Desktop clients   \n",
       "108                Foko Retail                          Browser   \n",
       "\n",
       "          deviceDetailbrowser deviceDetaildisplayName  \\\n",
       "0    Rich Client 3.19.8.16603          THOMASPRICE-LT   \n",
       "1           Chrome 100.0.4896         ATTACKTARGET-LT   \n",
       "2           Chrome 100.0.4896         ATTACKTARGET-LT   \n",
       "3           Chrome 100.0.4896         ATTACKTARGET-LT   \n",
       "4           Chrome 100.0.4896         ATTACKTARGET-LT   \n",
       "..                        ...                     ...   \n",
       "104         Chrome 100.0.4896         ATTACKTARGET-LT   \n",
       "105         Chrome 100.0.4896         ATTACKTARGET-LT   \n",
       "106             Edge 87.11424         DAVIDJOHNSON-LT   \n",
       "107         Chrome 100.0.4896         ATTACKTARGET-LT   \n",
       "108      Rich Client 4.39.0.0                    <NA>   \n",
       "\n",
       "    deviceDetailoperatingSystem statusfailureReason  logcount  ...  \\\n",
       "0                    Windows 10                <NA>         3  ...   \n",
       "1                    Windows 10                <NA>         0  ...   \n",
       "2                    Windows 10                <NA>         2  ...   \n",
       "3                    Windows 10                <NA>         3  ...   \n",
       "4                    Windows 10                <NA>         4  ...   \n",
       "..                          ...                 ...       ...  ...   \n",
       "104                  Windows 10                <NA>        16  ...   \n",
       "105                  Windows 10                <NA>         9  ...   \n",
       "106                  Windows 10                <NA>         0  ...   \n",
       "107                  Windows 10                <NA>        10  ...   \n",
       "108                   Windows10                <NA>         0  ...   \n",
       "\n",
       "     locincrement_loss  logcount_z_loss               clientAppUsed_pred  \\\n",
       "0             0.610670         0.027359  Mobile Apps and Desktop clients   \n",
       "1             5.914863         0.633756  Mobile Apps and Desktop clients   \n",
       "2             5.936103         0.109216  Mobile Apps and Desktop clients   \n",
       "3             5.942259         0.376158  Mobile Apps and Desktop clients   \n",
       "4             5.936529         0.562854  Mobile Apps and Desktop clients   \n",
       "..                 ...              ...                              ...   \n",
       "104           6.032503         2.419621  Mobile Apps and Desktop clients   \n",
       "105           0.503085         0.252396  Mobile Apps and Desktop clients   \n",
       "106           0.514629         0.155598  Mobile Apps and Desktop clients   \n",
       "107           0.535288         0.019980  Mobile Apps and Desktop clients   \n",
       "108           0.507879         0.192614  Mobile Apps and Desktop clients   \n",
       "\n",
       "    clientAppUsed_loss  appDisplayName_loss  statusfailureReason_loss  \\\n",
       "0             1.174857             2.780367                  1.605560   \n",
       "1             0.591306             1.697818                  0.607544   \n",
       "2             0.603926             1.713131                  0.621300   \n",
       "3             0.599671             1.697026                  0.614225   \n",
       "4             0.589449             1.683457                  0.599916   \n",
       "..                 ...                  ...                       ...   \n",
       "104           0.418121             1.608195                  0.420876   \n",
       "105           0.807381             4.478906                  1.358579   \n",
       "106           0.799728             4.384770                  1.430044   \n",
       "107           0.783910             4.378347                  1.345962   \n",
       "108           1.292141             4.207778                  1.424070   \n",
       "\n",
       "     appincrement_loss  appDisplayName_z_loss  \\\n",
       "0             0.735984               1.979742   \n",
       "1             2.277889               2.968441   \n",
       "2             3.988265               2.393491   \n",
       "3            14.026583               2.998179   \n",
       "4            30.273712               3.507625   \n",
       "..                 ...                    ...   \n",
       "104         619.997925               6.333486   \n",
       "105          31.562899               1.308199   \n",
       "106          36.937981               0.934225   \n",
       "107          43.152668               0.908708   \n",
       "108          42.751469               0.231083   \n",
       "\n",
       "                           model_version            event_time  \n",
       "0          DFP-azure-tprice@domain.com:1  2023-07-20T20:24:22Z  \n",
       "1    DFP-azure-attacktarget@domain.com:2  2023-07-20T20:25:09Z  \n",
       "2    DFP-azure-attacktarget@domain.com:2  2023-07-20T20:25:09Z  \n",
       "3    DFP-azure-attacktarget@domain.com:2  2023-07-20T20:25:09Z  \n",
       "4    DFP-azure-attacktarget@domain.com:2  2023-07-20T20:25:09Z  \n",
       "..                                   ...                   ...  \n",
       "104  DFP-azure-attacktarget@domain.com:2  2023-07-20T20:26:07Z  \n",
       "105            DFP-azure-generic_user:53  2023-07-20T20:26:10Z  \n",
       "106            DFP-azure-generic_user:53  2023-07-20T20:26:10Z  \n",
       "107            DFP-azure-generic_user:53  2023-07-20T20:26:10Z  \n",
       "108            DFP-azure-generic_user:53  2023-07-20T20:26:10Z  \n",
       "\n",
       "[109 rows x 44 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = cudf.read_csv(\"dfp_detections_azure.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689655f0-51ce-43a7-81bf-5e9ee2521911",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:morpheus] *",
   "language": "python",
   "name": "conda-env-morpheus-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
